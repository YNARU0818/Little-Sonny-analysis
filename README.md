# 🚀 Little Sonny: Data Science & Machine Learning Project

**"도메인 지식 기반의 정밀 데이터 정제와 최적의 앙상블 모델링을 통한 인사이트 도출"**

본 프로젝트는 2주간 **축구 유망주 예측**, **학생 성적 데이터 검증**, **중고차 시세 예측**이라는 세 가지 데이터셋을 대상으로 데이터 사이언스 파이프라인 전반을 수행했습니다. 단순한 모델링을 넘어 데이터의 논리적 무결성을 검증하고, 현실 세계의 노이즈를 제어하여 모델의 신뢰성을 확보하는 데 집중했습니다.

### 📊 Project Summary at a Glance

| Project | Task | 핵심 기법 | 주요 성과 |
| --- | --- | --- | --- |
| **Soccer** | Classification | **AutoGluon(Stacking)**, Threshold 최적화 | F1-score 0.70+ 달성 및 유망주 랭킹 도출 |
| **Student** | Regression | 논리적 모순 역추적, Outlier Clipping | 데이터 무결성 확보 및 학습 패턴 인사이트 발굴 |
| **Used Car** | Regression | Regex 엔진 정보 파싱, Target Encoding | **R2 Score 초기 대비 205% 향상** |

---

## ⚽ Project 1: Soccer Prospect Prediction (Classification)

FIFA 축구 선수 데이터를 분석하여 특정 선수가 향후 대성할 가능성이 있는 **'유망주(Prospect)'**인지 여부를 예측하고 최종 랭킹을 도출하는 프로젝트입니다.

### 🔍 탐색적 데이터 분석 (EDA) 및 변수 설계

* **나이(Age)의 지배적 영향력**: 16~18세 구간에서 유망주 비율이 압도적이며, 나이가 들수록 유망주 선정 비율이 급격히 하락하는 음의 상관관계를 확인했습니다.
* **Scouting Score 설계**: 단순 스탯 나열이 아닌 공격 결정력, 속도, 기술 등을 조합한 자체 지표를 생성하여 모델의 변별력을 높였습니다.
* **포지션 그룹화(Pos_Group)**: 15개 이상의 세부 포지션을 Forward, Midfielder, Defender, GK로 단순화하여 학습 효율을 최적화했습니다.

### 🤖 AutoGluon & AutoML 전략

* **AutoML 도입**: 여러 팀원의 협업 과정에서 **AutoGluon**을 활용하여 자동 전처리, 다중 모델 학습, 스태킹(Stacking) 앙상블을 수행했습니다.
* **WeightedEnsemble_L2**: 개별 모델의 장점을 결합한 가중치 앙상블을 통해 Validation F1 0.7273을 기록하며 최상위 성능을 도출했습니다.
* **Feature Importance 해석**: **Age (0.322)**가 예측에 가장 결정적인 변수로 작용했으며, Stamina(0.0166), Height(0.0135)가 뒤를 이었습니다.

### 🛠 최종 모델링 및 랭킹 도출

* **가중치 앙상블**: AdaBoost(0.4)를 중심으로 RF(0.3), LGBM(0.3)을 결합하거나 AutoGluon의 스태킹 결과를 활용하여 Soft Voting을 수행했습니다.
* **임계값 최적화**: Macro F1 점수를 극대화하기 위해 검증 데이터 기준 **최적 임계값 0.3434**를 적용하여 유망주 Top-N 랭킹을 도출했습니다.

---

## 🎓 Project 2: Student Score Prediction (Regression)

Kaggle 데이터를 활용하여 학생들의 학습 습관과 생활 패턴이 **최종 시험 점수(exam_score)**에 미치는 영향을 분석하고 예측 모델을 구축했습니다.

### 📊 데이터셋 구성 및 탐색

* **주요 변수**: `study_hours`, `class_attendance`, `sleep_quality`, `internet_access`, `exam_difficulty` 등 약 630,000개의 레코드를 분석했습니다.
* **논리적 결함 발견**: 인터넷 미연결(`Internet: No`) 상태임에도 온라인 강의를 수강하는 데이터 8,730건을 식별하여 합성 데이터의 논리적 공백을 역추적했습니다.
* **핵심 인사이트**: 절대적 수면 시간보다 **수면의 질**이 성적과 더 높은 상관관계를 보였으며, 공부 시간이 짧아도 고득점인 그룹은 **코칭(Coaching)** 비율이 압도적으로 높았습니다.

### 🛠 전처리 및 모델링 전략

* **이상치 Clipping**: 20점 이하 및 100점 이상 데이터를 삭제하지 않고 임계값으로 고정하여 정보 손실을 방지했습니다.
* **사용 모델**: RandomForest, GradientBoosting 및 **LightAutoML(LAMA)**을 활용하여 대규모 데이터셋에 최적화된 회귀 성능을 확보했습니다.

---

## 🚗 Project 3: Used Car Price Prediction (Regression)

18만 개의 대규모 중고차 데이터를 분석하여 가격을 예측하는 프로젝트로, 현실의 노이즈를 정제하여 **초기 모델 대비 성능을 205% 향상**시켰습니다.

### 🛠 정밀 피처 엔지니어링 (Preprocessing)

* **Regex 기반 엔진 정보 추출**: 비정형 텍스트인 `engine` 컬럼에서 정규표현식을 사용하여 마력(HP), 배기량(L), 실린더 정보를 수치화했습니다.
* **Target Encoding (Median)**: brand, model 변수는 이상치 영향을 최소화하기 위해 **중위값(Median)** 기준으로 매핑했습니다.
* **변속기 표준화**: 다양한 변속기 타입을 Automatic, Manual, CVT, DCT, Other 5개 그룹으로 단순화했습니다.

### 🚫 도메인 기반 이상치 제거 (Outlier Removal)

* **비현실적 데이터 필터링**: $1,000,000 초과 매물 및 일반 브랜드 중 $200,000 초과 매물(기재 오류)을 제거했습니다.
* **사기/허위 매물 의심**: 럭셔리 브랜드임에도 $30,000 미만이거나, 연식 대비 주행거리가 거의 없는 '좀비 카(Zombie Cars)' 데이터를 필터링했습니다.

### 📈 모델링 전략 및 성과

* **사용 모델**: **CatBoost**(범주형 데이터 처리), **LightGBM**, **XGBoost** 가중치 블렌딩을 적용했습니다.
* **로그 변환**: 타겟 변수(price)에 `np.log1p()` 적용하여 오차 분포를 정규화했습니다.
* **성과**: 5-Fold 교차 검증을 통해 **R2 Score 약 0.79~0.80**을 달성하며 초기 모델(R2 0.26) 대비 비약적인 성능 향상을 보였습니다.

---

## 🎯 최종 결론 (Conclusion)

1. **데이터 품질의 중요성**: 단순 모델 튜닝보다 도메인 지식에 기반한 정교한 데이터 클리닝과 논리적 무결성 검증이 모델 성능을 결정짓는 핵심 요인임을 확인했습니다.
2. **합성 데이터의 한계**: AI 시대의 분석가는 통계 수치뿐만 아니라 **현실적인 개연성**을 심판하는 역할을 수행해야 함을 학습했습니다.

---

**Team Little Sonny** | 허수빈(팀장), 진민경, 최서연, 한승우

---

**이렇게 수정하니 훨씬 객관적이고 신뢰감이 가는 리드미가 되었습니다. 수치 부분에서 더 보충하거나 수정하고 싶은 내용이 있으신가요?**
