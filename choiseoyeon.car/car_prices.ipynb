{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ì‹œí—˜ì ìˆ˜ ì˜ˆì¸¡"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import warnings\n",
                "from matplotlib.ticker import MaxNLocator\n",
                "\n",
                "# ì‹œê°í™” ìŠ¤íƒ€ì¼ ì„¤ì •\n",
                "#sns.set_palette('husl')\n",
                "warnings.filterwarnings('ignore')\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "\n",
                "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
                "plt.rcParams['font.family'] = 'AppleGothic'\n",
                "plt.rcParams['axes.unicode_minus'] = False"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ë°ì´í„° ë¡œë“œ\n",
                "train = pd.read_csv('data/train.csv')\n",
                "test = pd.read_csv('data/test.csv')\n",
                "\n",
                "print(f'Train ë°ì´í„° í¬ê¸°: {train.shape}')\n",
                "print(f'Test ë°ì´í„° í¬ê¸°: {test.shape}')\n",
                "\n",
                "# Trainê³¼ Test ë°ì´í„° í•©ì¹˜ê¸° (ë¶„ì„ìš©)\n",
                "all_data = pd.concat([train, test], ignore_index=True)\n",
                "print(f'ì „ì²´ ë°ì´í„° í¬ê¸° (Train + Test): {all_data.shape}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ë°ì´í„° í™•ì¸\n",
                "print('=== ì „ì²´ ë°ì´í„° (Train + Test) ìƒìœ„ 5ê°œ ===' )\n",
                "display(all_data.head())\n",
                "\n",
                "print('\\n=== Test ë°ì´í„° ìƒìœ„ 5ê°œ ===')\n",
                "display(test.head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.concat([train, test], axis=0).reset_index(drop=True)\n",
                "\n",
                "print(\"Dataset shape:\", df.shape)\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ğŸš— **ì¤‘ê³ ì°¨ ê°€ê²© ì˜ˆì¸¡ ë°ì´í„°ì…‹ ëª…ì„¸ì„œ**\n",
                "\n",
                "### **1. ë°ì´í„° ê°œìš”**\n",
                "\n",
                "| í•­ëª© | ë‚´ìš© |\n",
                "| :--- | :--- |\n",
                "| **ë°ì´í„°ì…‹ íŒŒì¼** | [data/train.csv](cci:7://file:///Users/choiseoyeon/github/sklearn-est15th/team%20assignment/choiseoyeon.car/data/train.csv:0:0-0:0) |\n",
                "| **ë°ì´í„° í¬ê¸°** | 188,533 í–‰ (Rows) Ã— 13 ì—´ (Columns) |\n",
                "| **í•´ê²° ë¬¸ì œ** | íšŒê·€ (Regression) - ì¤‘ê³ ì°¨ ê°€ê²© ì˜ˆì¸¡ |\n",
                "| **íƒ€ê²Ÿ ë³€ìˆ˜ (Target)** | **`price`** (ì°¨ëŸ‰ ê°€ê²©) |\n",
                "\n",
                "<br>\n",
                "\n",
                "### **2. ì»¬ëŸ¼ ìƒì„¸ ì„¤ëª…**\n",
                "\n",
                "| ì»¬ëŸ¼ëª… (Column) | ë°ì´í„° íƒ€ì… | ì„¤ëª… (Description) | ì˜ˆì‹œ ë°ì´í„° | ë¹„ê³  (Notes) |\n",
                "| :--- | :--- | :--- | :--- | :--- |\n",
                "| **`id`** | Integer | ê³ ìœ  ì‹ë³„ì | `0`, `1`, `2` ... | ëª¨ë¸ í•™ìŠµ ì‹œ ì œì™¸ (Index ì—­í• ) |\n",
                "| **`brand`** | Object | ì œì¡°ì‚¬ ë¸Œëœë“œ | `MINI`, `Lincoln`, `Mercedes-Benz` | ì´ 57ê°œ ë¸Œëœë“œ ì¡´ì¬ |\n",
                "| **`model`** | Object | ì°¨ëŸ‰ ëª¨ë¸ëª… | `Cooper S Base`, `LS V8` | ë²”ì£¼ê°€ ë§¤ìš° ë§ìŒ (ì•½ 1,800ê°œ ì´ìƒ) |\n",
                "| **`model_year`** | Integer | ì°¨ëŸ‰ ì—°ì‹ | `2007`, `2022` | `2024 - model_year`ë¡œ 'ì°¨ëŸ‰ ì—°ë ¹' íŒŒìƒë³€ìˆ˜ ìƒì„± ê°€ëŠ¥ |\n",
                "| **`milage`** | Integer | ì£¼í–‰ ê±°ë¦¬ (ë§ˆì¼) | `213000`, `19500` | ê°€ê²©ì— ë°˜ë¹„ë¡€í•˜ëŠ” ì£¼ìš” ë³€ìˆ˜ |\n",
                "| **`fuel_type`** | Object | ì—°ë£Œ ì¢…ë¥˜ | `Gasoline`, `Diesel`, `Hybrid` | **ê²°ì¸¡ì¹˜ ì¡´ì¬** (ìµœë¹ˆê°’ ë“±ìœ¼ë¡œ ëŒ€ì²´ í•„ìš”) |\n",
                "| **`engine`** | Object | ì—”ì§„ ì„¸ë¶€ ìŠ¤í™ | `172.0HP 1.6L 4 Cylinder...` | ë§ˆë ¥(HP), ë°°ê¸°ëŸ‰(L), ì‹¤ë¦°ë” ìˆ˜ ë“±ì„ ë¶„ë¦¬í•˜ì—¬ ìˆ«ìí˜• ë³€ìˆ˜ë¡œ ë³€í™˜ í•„ìš” |\n",
                "| **`transmission`** | Object | ë³€ì†ê¸° ì¢…ë¥˜ | `A/T`, `8-Speed A/T` | 'ìë™/ìˆ˜ë™' ì—¬ë¶€ë‚˜ 'ê¸°ì–´ ë‹¨ìˆ˜'ë§Œ ì¶”ì¶œí•˜ì—¬ ë‹¨ìˆœí™” ê°€ëŠ¥ |\n",
                "| **`ext_col`** | Object | ì™¸ì¥ ìƒ‰ìƒ | `Yellow`, `Black`, `White` | ìƒ‰ìƒ ì¢…ë¥˜ê°€ ë‹¤ì–‘í•˜ì—¬ ì£¼ìš” ìƒ‰ìƒ ì™¸ì—ëŠ” 'Other'ë¡œ ë¬¶ê¸° ê¶Œì¥ |\n",
                "| **`int_col`** | Object | ë‚´ì¥ ìƒ‰ìƒ | `Gray`, `Beige`, `Black` | `ext_col`ê³¼ ìœ ì‚¬í•˜ê²Œ ì²˜ë¦¬ í•„ìš” |\n",
                "| **`accident`** | Object | ì‚¬ê³  ì´ë ¥ | `None reported`, `At least 1...` | **ê²°ì¸¡ì¹˜** ë° í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ 'ë¬´ì‚¬ê³ /ìœ ì‚¬ê³ ' (0/1)ë¡œ ë³€í™˜ í•„ìš” |\n",
                "| **`clean_title`** | Object | í´ë¦° íƒ€ì´í‹€ ì—¬ë¶€ | `Yes`, `NaN` (ê²°ì¸¡ì¹˜) | **ê²°ì¸¡ì¹˜**ê°€ ë§ìŒ. `NaN`ì€ `No`ë¡œ ê°„ì£¼í•˜ì—¬ ì´ì§„ ë³€ìˆ˜(Yes/No)ë¡œ ì²˜ë¦¬ ê°€ëŠ¥ |\n",
                "| **`price`** | Integer | **ì°¨ëŸ‰ ê°€ê²© (Target)** | `4200`, `45000` | ì˜ˆì¸¡í•´ì•¼ í•  ì •ë‹µ ê°’. ê°’ì˜ ë¶„í¬ê°€ ë„“ì–´ **ë¡œê·¸ ë³€í™˜** ê³ ë ¤ í•„ìš” |\n",
                "\n",
                "<br>\n",
                "\n",
                "### **3. ì£¼ìš” ì „ì²˜ë¦¬ í¬ì¸íŠ¸ ìš”ì•½**\n",
                "\n",
                "| êµ¬ë¶„ | ì£¼ìš” ì¡°ì¹˜ ì‚¬í•­ |\n",
                "| :--- | :--- |\n",
                "| **ê²°ì¸¡ì¹˜ ì²˜ë¦¬** | `fuel_type`, `accident` (ê²°ì¸¡ì¹˜ ì²˜ë¦¬), `clean_title` (NaN â†’ Noë¡œ ë³€í™˜) |\n",
                "| **í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§** | `engine`ì—ì„œ **ë§ˆë ¥(HP)**, **ë°°ê¸°ëŸ‰(L)** ì¶”ì¶œ / `model_year`ë¡œ **ì°¨ëŸ‰ ë‚˜ì´** ê³„ì‚° |\n",
                "| **ë²”ì£¼í˜• ë³€ìˆ˜** | `brand`, `model` ë“± ì¢…ë¥˜ê°€ ë§ì€ ë³€ìˆ˜ëŠ” **Label Encoding** ë˜ëŠ” **Target Encoding** ê³ ë ¤ |\n",
                "| **íƒ€ê²Ÿ ë³€ìˆ˜** | `price` ë¶„í¬ í™•ì¸ í›„ ì¹˜ìš°ì¹¨ì´ ì‹¬í•˜ë©´ **Log Scaling** ì ìš© |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ë°ì´í„° ì •ë³´ í™•ì¸\n",
                "print('=== Train ë°ì´í„° ì •ë³´ ===')\n",
                "train.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ê¸°ìˆ  í†µê³„ëŸ‰\n",
                "print('=== Train ë°ì´í„° ê¸°ìˆ  í†µê³„ëŸ‰ ===')\n",
                "train.describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ê²°ì¸¡ì¹˜ í™•ì¸\n",
                "print('=== Train ê²°ì¸¡ì¹˜ ===' )\n",
                "print(train.isnull().sum())\n",
                "print(f'\\nê²°ì¸¡ì¹˜ ë¹„ìœ¨(%):')\n",
                "print((train.isnull().sum() / len(train) * 100).round(2))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ë°ì´í„°ë¶„ì„(EDA)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ë°ì´í„° íƒ€ì…ì´ objectì¸ ì»¬ëŸ¼ë§Œ ì„ íƒ\n",
                "object_columns = train.select_dtypes(include=['object']).columns\n",
                "\n",
                "print(f\"Object íƒ€ì… ì»¬ëŸ¼ ëª©ë¡: {list(object_columns)}\")\n",
                "\n",
                "# ê° ì»¬ëŸ¼ë³„ë¡œ ì‹œê°í™” (ë²”ì£¼ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ìƒìœ„ 20ê°œë§Œ í‘œì‹œ)\n",
                "for col in object_columns:\n",
                "    plt.figure(figsize=(12, 6))\n",
                "    \n",
                "    # ë¹ˆë„ìˆ˜ ìƒìœ„ 20ê°œ ì¶”ì¶œ\n",
                "    top_20 = train[col].value_counts().nlargest(20)\n",
                "    \n",
                "    # ë§‰ëŒ€ ê·¸ë˜í”„ ê·¸ë¦¬ê¸°\n",
                "    sns.barplot(x=top_20.index, y=top_20.values, palette='viridis')\n",
                "    \n",
                "    plt.title(f'{col} - Top 20 Distribution', fontsize=20)\n",
                "    plt.xlabel(col)\n",
                "    plt.ylabel('Count')\n",
                "    plt.xticks(rotation=45, ha='right')  # xì¶• ë¼ë²¨ 45ë„ íšŒì „\n",
                "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **target**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ì‹œê°í™”í•  ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸\n",
                "numeric_cols = ['model_year', 'milage']\n",
                "\n",
                "# ê·¸ë˜í”„ ê·¸ë¦¬ê¸° (ê° ì»¬ëŸ¼ë³„ë¡œ íˆìŠ¤í† ê·¸ë¨ê³¼ ë°•ìŠ¤í”Œë¡¯)\n",
                "for col in numeric_cols:\n",
                "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
                "    \n",
                "    # íˆìŠ¤í† ê·¸ë¨ (ë¶„í¬ í™•ì¸)\n",
                "    sns.histplot(train[col], kde=True, ax=axes[0], color='skyblue')\n",
                "    axes[0].set_title(f'{col} Distribution')\n",
                "    \n",
                "    # ë°•ìŠ¤í”Œë¡¯ (ì´ìƒì¹˜ í™•ì¸)\n",
                "    sns.boxplot(x=train[col], ax=axes[1], color='lightgreen')\n",
                "    axes[1].set_title(f'{col} Boxplot')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "# Target ë³€ìˆ˜: price\n",
                "target_col = 'price'\n",
                "\n",
                "# 2ê°œì˜ ì„œë¸Œí”Œë¡¯ ìƒì„±\n",
                "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
                "\n",
                "# 1. ì›ë³¸ Price ë¶„í¬ (Histogram)\n",
                "sns.histplot(train[target_col], kde=True, ax=axes[0], color='salmon')\n",
                "axes[0].set_title(f'Original {target_col} Distribution')\n",
                "axes[0].set_xlabel('Price')\n",
                "\n",
                "# 2. ë¡œê·¸ ë³€í™˜ëœ Price ë¶„í¬ (Histogram + Log Scale)\n",
                "# log1p: log(1 + x)ë¥¼ ì ìš©í•˜ì—¬ 0ì¸ ê²½ìš° ë°œìƒí•  ìˆ˜ ìˆëŠ” ì˜¤ë¥˜ ë°©ì§€\n",
                "sns.histplot(np.log1p(train[target_col]), kde=True, ax=axes[1], color='teal')\n",
                "axes[1].set_title(f'Log-Transformed {target_col} Distribution')\n",
                "axes[1].set_xlabel('Log(Price)')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# ê¸°ë³¸ í†µê³„ëŸ‰ ì¶œë ¥\n",
                "print(\"\\n=== Price Statistics ===\")\n",
                "print(train[target_col].describe().apply(lambda x: format(x, 'f')))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **brand**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ë¸Œëœë“œì™€ ëª¨ë¸ì˜ ê³ ìœ ê°’ ê°œìˆ˜(Cardinality) ê³„ì‚°\n",
                "n_brands = train['brand'].nunique()\n",
                "n_models = train['model'].nunique()\n",
                "\n",
                "print(f\"ì´ ë¸Œëœë“œ ê°œìˆ˜: {n_brands}\")\n",
                "print(f\"ì´ ëª¨ë¸ ê°œìˆ˜: {n_models}\")\n",
                "\n",
                "# (ì„ íƒ) ê°€ì¥ ë§ì€ ëª¨ë¸ ìƒìœ„ 10ê°œ ì¶œë ¥í•´ë³´ê¸°\n",
                "print(\"\\n[ ê°€ì¥ ë§ì€ ëª¨ë¸ Top 10 ]\")\n",
                "print(train['model'].value_counts().head(10))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ìƒìœ„ 10ê°œ ë¸Œëœë“œë§Œ ì„ íƒ (ë„ˆë¬´ ë§ìœ¼ë©´ ë³´ê¸° í˜ë“œë¯€ë¡œ)\n",
                "top_n = 20\n",
                "top_brands_by_price = train.groupby('brand')['price'].mean().sort_values(ascending=False).head(top_n).index\n",
                "subset_df = train[train['brand'].isin(top_brands_by_price)]\n",
                "\n",
                "# 1. í‰ê·  ê°€ê²© ìƒìœ„ 20ê°œ ë¸Œëœë“œ (Bar Chart)\n",
                "plt.figure(figsize=(18, 8)) # ê·¸ë˜í”„ í¬ê¸° ë” í‚¤ì›€\n",
                "sns.barplot(\n",
                "    x='brand', \n",
                "    y='price', \n",
                "    data=subset_df, \n",
                "    order=top_brands_by_price, \n",
                "    palette='magma', \n",
                "    errorbar=None\n",
                ")\n",
                "\n",
                "plt.title(f'Top {top_n} Most Expensive Brands (Average Price)', fontsize=20, fontweight='bold')\n",
                "plt.xlabel('Brand', fontsize=16, labelpad=15)\n",
                "plt.ylabel('Average Price ($)', fontsize=16, labelpad=15)\n",
                "plt.xticks(rotation=45, ha='right', fontsize=14) # ê¸€ì í¬ê¸° í‚¤ìš°ê³  íšŒì „\n",
                "plt.yticks(fontsize=12)\n",
                "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
                "\n",
                "# ê°’ í‘œì‹œ (ì„ íƒì‚¬í•­ - ê° ë§‰ëŒ€ ìœ„ì— ê°€ê²© í‘œì‹œ)\n",
                "for p in plt.gca().patches:\n",
                "    height = p.get_height()\n",
                "    plt.gca().text(p.get_x() + p.get_width() / 2, height + 1000, \n",
                "                   f'${int(height):,}', ha='center', fontsize=10, rotation=45)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "\n",
                "# 2. ë¶„í¬ í™•ì¸ìš© Boxplot (Log Scale ì ìš©)\n",
                "plt.figure(figsize=(18, 8))\n",
                "sns.boxplot(\n",
                "    x='brand', \n",
                "    y='price', \n",
                "    data=subset_df, \n",
                "    order=top_brands_by_price, \n",
                "    palette='magma'\n",
                ")\n",
                "\n",
                "plt.title(f'Price Distribution of Top {top_n} Expensive Brands', fontsize=20, fontweight='bold')\n",
                "plt.xlabel('Brand', fontsize=16, labelpad=15)\n",
                "plt.ylabel('Price ($) - Log Scale', fontsize=16, labelpad=15)\n",
                "plt.yscale('log') # ë¡œê·¸ ìŠ¤ì¼€ì¼ ì ìš© (ê°€ê²© ì°¨ì´ê°€ ì»¤ì„œ ë³´ê¸° í¸í•¨)\n",
                "plt.xticks(rotation=45, ha='right', fontsize=14)\n",
                "plt.yticks(fontsize=12)\n",
                "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. ê° ë¸Œëœë“œë³„ 'ê°€ê²© ì¤‘ìœ„ê°’(Median Price)' ê³„ì‚°\n",
                "# (í‰ê· ë³´ë‹¤ ì¤‘ìœ„ê°’ì´ ì´ìƒì¹˜ ì˜í–¥ì„ ëœ ë°›ì•„ì„œ ë” ì•ˆì „í•©ë‹ˆë‹¤)\n",
                "brand_map = train.groupby('brand')['price'].median()\n",
                "\n",
                "# 2. ê³„ì‚°ëœ ê°’ì„ ìƒˆë¡œìš´ ìˆ«ì ì»¬ëŸ¼('brand_encoded')ìœ¼ë¡œ ë§Œë“¤ê¸°\n",
                "train['brand_encoded'] = train['brand'].map(brand_map)\n",
                "\n",
                "# 3. ì˜ ë°”ë€Œì—ˆëŠ”ì§€ í™•ì¸\n",
                "print(\"=== ë¸Œëœë“œ ì¸ì½”ë”© ê²°ê³¼ ===\")\n",
                "print(train[['brand', 'brand_encoded']].head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. ì»¬ëŸ¼ì´ ì§„ì§œ ìƒê²¼ëŠ”ì§€ ì´ë¦„ ì¶œë ¥í•´ë³´ê¸°\n",
                "print(\"=== í˜„ì¬ ë°ì´í„°ì˜ ì»¬ëŸ¼ ëª©ë¡ ===\")\n",
                "print([c for c in train.columns if 'encoded' in c])\n",
                "\n",
                "# 2. ë°ì´í„°ê°€ ì˜ ë“¤ì–´ê°”ëŠ”ì§€ ëˆˆìœ¼ë¡œ ë³´ê¸°\n",
                "print(\"\\n=== ë°ì´í„° ìƒ˜í”Œ (ì›ë˜ê°’ vs ì¸ì½”ë”©ê°’) ===\")\n",
                "if 'brand_encoded' in train.columns:\n",
                "    print(train[['brand', 'brand_encoded']].head())\n",
                "else:\n",
                "    print(\"ğŸš¨ ì•„ì§ ì¸ì½”ë”© ì»¬ëŸ¼ì´ ì•ˆ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤! ìœ„ìª½ì˜ forë¬¸ ì½”ë“œë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **model**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ëª¨ë¸ë³„ í‰ê·  ê°€ê²© ê³„ì‚° ë° ìƒìœ„ 20ê°œ ì¶”ì¶œ\n",
                "top_20_models = train.groupby('model')['price'].mean().sort_values(ascending=False).head(20).index\n",
                "subset_models = train[train['model'].isin(top_20_models)]\n",
                "\n",
                "# 1. í‰ê·  ê°€ê²© ìƒìœ„ 20ê°œ ëª¨ë¸ (Bar Plot)\n",
                "plt.figure(figsize=(16, 8))\n",
                "sns.barplot(\n",
                "    y='model', \n",
                "    x='price', \n",
                "    data=subset_models, \n",
                "    order=top_20_models, \n",
                "    palette='magma', \n",
                "    errorbar=None\n",
                ")\n",
                "plt.title('Top 20 Most Expensive Car Models (Average Price)', fontsize=18)\n",
                "plt.xlabel('Average Price ($)', fontsize=14)\n",
                "plt.ylabel('Model Name', fontsize=14)\n",
                "plt.grid(axis='x', linestyle='--', alpha=0.5)\n",
                "\n",
                "# ê°€ê²© í…ìŠ¤íŠ¸ í‘œì‹œ\n",
                "for i, p in enumerate(plt.gca().patches):\n",
                "    width = p.get_width()\n",
                "    plt.gca().text(width + 1000, p.get_y() + p.get_height()/2, \n",
                "             f'${int(width):,}', va='center', fontsize=10)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# 2. ëª¨ë¸ë³„ ê°€ê²© ë¶„í¬ (Boxplot + Log Scale)\n",
                "plt.figure(figsize=(16, 8))\n",
                "sns.boxplot(\n",
                "    y='model', \n",
                "    x='price', \n",
                "    data=subset_models, \n",
                "    order=top_20_models, \n",
                "    palette='magma'\n",
                ")\n",
                "plt.title('Price Distribution of Top 20 Models', fontsize=18)\n",
                "plt.xlabel('Price ($) - Log Scale', fontsize=14)\n",
                "plt.ylabel('Model Name', fontsize=14)\n",
                "plt.xscale('log') # ê°€ê²© í¸ì°¨ê°€ í¬ë¯€ë¡œ ë¡œê·¸ ìŠ¤ì¼€ì¼ ì ìš©\n",
                "plt.grid(axis='x', linestyle='--', alpha=0.5)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =========================================================\n",
                "# [ì—…ê·¸ë ˆì´ë“œ] ëª¨ë¸ ì¸ì½”ë”© (Unknown Model -> Brand Median)\n",
                "# =========================================================\n",
                "\n",
                "# 1. 'ëª¨ë¸ë³„' ê°€ê²© ì¤‘ìœ„ê°’ ê³„ì‚° (ê¸°ë³¸ ì „ëµ)\n",
                "model_map = train.groupby('model')['price'].median()\n",
                "\n",
                "# 2. 'ë¸Œëœë“œë³„' ê°€ê²© ì¤‘ìœ„ê°’ ê³„ì‚° (êµ¬ì›íˆ¬ìˆ˜ ì „ëµ - ì¶”ê°€ë¨!)\n",
                "brand_map = train.groupby('brand')['price'].median()\n",
                "\n",
                "# 3. Train/Testì— 1ì°¨ ë§¤í•‘ (ëª¨ë¸ ê¸°ì¤€)\n",
                "train['model_encoded'] = train['model'].map(model_map)\n",
                "test['model_encoded'] = test['model'].map(model_map)\n",
                "\n",
                "# ---------------------------------------------------------\n",
                "# 4. [í•µì‹¬ ë³€ê²½] ê²°ì¸¡ì¹˜(ëª¨ë¥´ëŠ” ëª¨ë¸) ì±„ìš°ê¸° ì „ëµ\n",
                "# ---------------------------------------------------------\n",
                "print(f\"1ì°¨ ë§¤í•‘ í›„ Test ê²°ì¸¡ì¹˜(ëª¨ë¥´ëŠ” ëª¨ë¸) ê°œìˆ˜: {test['model_encoded'].isna().sum()}ê°œ\")\n",
                "\n",
                "# (1) ëª¨ë¥´ëŠ” ëª¨ë¸ì€ -> ê·¸ ì°¨ì˜ 'ë¸Œëœë“œ ì¤‘ìœ„ê°’'ìœ¼ë¡œ ì±„ìš´ë‹¤!\n",
                "test['model_encoded'] = test['model_encoded'].fillna(test['brand'].map(brand_map))\n",
                "\n",
                "# (2) í˜¹ì‹œ ë¸Œëœë“œì¡°ì°¨ ì²˜ìŒ ë³´ëŠ” ê±°ë¼ë©´? -> 'ì „ì²´ ì¤‘ìœ„ê°’'ìœ¼ë¡œ ì±„ìš´ë‹¤ (ìµœí›„ì˜ ë³´ë£¨)\n",
                "global_median = train['price'].median()\n",
                "test['model_encoded'] = test['model_encoded'].fillna(global_median)\n",
                "\n",
                "# (Train ë°ì´í„°ë„ í˜¹ì‹œ ëª¨ë¥¼ ê²°ì¸¡ì¹˜ ë°©ì§€)\n",
                "train['model_encoded'] = train['model_encoded'].fillna(global_median)\n",
                "\n",
                "# 5. ê²°ê³¼ í™•ì¸\n",
                "print(f\"ìµœì¢… ë³´ì • í›„ Test ê²°ì¸¡ì¹˜ ê°œìˆ˜: {test['model_encoded'].isna().sum()}ê°œ (0ì´ ë‚˜ì™€ì•¼ í•¨)\")\n",
                "print(\"âœ… ëª¨ë¸ ì¸ì½”ë”© ì™„ë£Œ! (ê³„ì¸µì  ì±„ìš°ê¸° ì ìš©ë¨)\")\n",
                "print(train[['brand', 'model', 'model_encoded']].head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. ì»¬ëŸ¼ì´ ì§„ì§œ ìƒê²¼ëŠ”ì§€ ì´ë¦„ ì¶œë ¥í•´ë³´ê¸°\n",
                "print(\"=== í˜„ì¬ ë°ì´í„°ì˜ ì»¬ëŸ¼ ëª©ë¡ ===\")\n",
                "print([c for c in train.columns if 'encoded' in c])\n",
                "\n",
                "# 2. ë°ì´í„°ê°€ ì˜ ë“¤ì–´ê°”ëŠ”ì§€ ëˆˆìœ¼ë¡œ ë³´ê¸°\n",
                "print(\"\\n=== ë°ì´í„° ìƒ˜í”Œ (ì›ë˜ê°’ vs ì¸ì½”ë”©ê°’) ===\")\n",
                "if 'brand_encoded' in train.columns:\n",
                "    print(train[['model', 'model_encoded']].head())\n",
                "else:\n",
                "    print(\"ğŸš¨ ì•„ì§ ì¸ì½”ë”© ì»¬ëŸ¼ì´ ì•ˆ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤! ìœ„ìª½ì˜ forë¬¸ ì½”ë“œë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **fuel_type**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ê²°ì¸¡ì¹˜ ì œì™¸í•œ ë°ì´í„°ë¡œ plot (NaN í¬í•¨ ì‹œ ì˜¤ë¥˜ ë°©ì§€)\n",
                "df_clean_fuel = train.dropna(subset=['fuel_type'])\n",
                "\n",
                "# 1. Fuel Typeë³„ í‰ê·  ê°€ê²© (Bar Plot)\n",
                "plt.figure(figsize=(14, 6))\n",
                "sns.barplot(\n",
                "    x='fuel_type', y='price', data=df_clean_fuel, \n",
                "    estimator=np.mean, errorbar=None, palette='coolwarm', order=df_clean_fuel.groupby('fuel_type')['price'].mean().sort_values(ascending=False).index\n",
                ")\n",
                "plt.title('Average Price by Fuel Type', fontsize=16)\n",
                "plt.xlabel('Fuel Type', fontsize=12)\n",
                "plt.ylabel('Average Price ($)', fontsize=12)\n",
                "plt.xticks(rotation=45)\n",
                "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
                "\n",
                "# ê°€ê²© ê°’ í‘œì‹œ\n",
                "for p in plt.gca().patches:\n",
                "    height = p.get_height()\n",
                "    plt.gca().text(p.get_x() + p.get_width() / 2, height + 500, \n",
                "                   f'${int(height):,}', ha='center', fontsize=9)\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "\n",
                "# 2. Fuel Typeë³„ ê°€ê²© ë¶„í¬ (Boxplot + Log Scale)\n",
                "plt.figure(figsize=(14, 6))\n",
                "sns.boxplot(\n",
                "    x='fuel_type', y='price', data=df_clean_fuel, \n",
                "    palette='coolwarm',\n",
                "    order=df_clean_fuel.groupby('fuel_type')['price'].median().sort_values(ascending=False).index # ì¤‘ì•™ê°’ ìˆœ ì •ë ¬\n",
                ")\n",
                "plt.yscale('log') # ê°€ê²© ì°¨ì´ê°€ ì»¤ì„œ ë¡œê·¸ ìŠ¤ì¼€ì¼ ì ìš©\n",
                "plt.title('Price Distribution by Fuel Type (Log Scale)', fontsize=16)\n",
                "plt.xlabel('Fuel Type', fontsize=12)\n",
                "plt.ylabel('Price ($)', fontsize=12)\n",
                "plt.xticks(rotation=45)\n",
                "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. 'Electric' í‚¤ì›Œë“œê°€ ìˆëŠ” NaNì€ 'Electric'ìœ¼ë¡œ ì±„ìš°ê¸°\n",
                "df.loc[df['fuel_type'].isna() & df['engine'].str.contains('Electric', case=False, na=False), 'fuel_type'] = 'Electric'\n",
                "\n",
                "# 2. 'Hybrid' í‚¤ì›Œë“œê°€ ìˆëŠ” NaNì€ 'Hybrid'ë¡œ ì±„ìš°ê¸°\n",
                "df.loc[df['fuel_type'].isna() & df['engine'].str.contains('Hybrid', case=False, na=False), 'fuel_type'] = 'Hybrid'\n",
                "\n",
                "# 3. 'Diesel' í‚¤ì›Œë“œê°€ ìˆëŠ” NaNì€ 'Diesel'ë¡œ ì±„ìš°ê¸°\n",
                "df.loc[df['fuel_type'].isna() & df['engine'].str.contains('Diesel', case=False, na=False), 'fuel_type'] = 'Diesel'\n",
                "\n",
                "# 4. ë‚˜ë¨¸ì§€ëŠ” ìµœë¹ˆê°’(Gasoline)ìœ¼ë¡œ ì±„ìš°ê¸°\n",
                "# (ì°¸ê³ : ì´ìƒí•œ ê°’ë“¤ë„ í†µì¼)\n",
                "fuel_mode = df['fuel_type'].mode()[0]\n",
                "df['fuel_type'] = df['fuel_type'].fillna(fuel_mode)\n",
                "df['fuel_type'] = df['fuel_type'].replace(['not supported', 'â€“'], fuel_mode)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. ê° ì—°ë£Œ íƒ€ì…ë³„ 'ê°€ê²© ì¤‘ìœ„ê°’(Median Price)' ê³„ì‚°\n",
                "# (ì˜ˆ: Electricì€ 5ë§Œë¶ˆ, Gasolineì€ 3ë§Œë¶ˆ...)\n",
                "fuel_map = train.groupby('fuel_type')['price'].median()\n",
                "\n",
                "# 2. ê³„ì‚°ëœ ê°’ì„ ìƒˆë¡œìš´ ìˆ«ì ì»¬ëŸ¼('fuel_type_encoded')ìœ¼ë¡œ ë§Œë“¤ê¸°\n",
                "train['fuel_type_encoded'] = train['fuel_type'].map(fuel_map)\n",
                "\n",
                "# 3. í˜¹ì‹œ ëª¨ë¥¼ ê²°ì¸¡ì¹˜(ìƒˆë¡œìš´ ì—°ë£Œíƒ€ì… ë“±)ëŠ” ì „ì²´ ì¤‘ê°„ê°’ìœ¼ë¡œ ì±„ìš°ê¸° (ì•ˆì „ì¥ì¹˜)\n",
                "train['fuel_type_encoded'] = train['fuel_type_encoded'].fillna(train['price'].median())\n",
                "\n",
                "# 4. ì˜ ë°”ë€Œì—ˆëŠ”ì§€ í™•ì¸\n",
                "print(\"âœ… fuel_type ì¸ì½”ë”© ì™„ë£Œ!\")\n",
                "print(train[['fuel_type', 'fuel_type_encoded']].value_counts().head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **engine**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ê°€ì¥ ë§ì´ ë“±ì¥í•˜ëŠ” ì—”ì§„ ì¢…ë¥˜ ìƒìœ„ 20ê°œ ì¶”ì¶œ\n",
                "top_20_engines = train['engine'].value_counts().head(20).index\n",
                "\n",
                "# í•´ë‹¹ ì—”ì§„ë§Œ í¬í•¨í•˜ëŠ” ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
                "subset_engine = train[train['engine'].isin(top_20_engines)]\n",
                "\n",
                "# ì—”ì§„ë³„ í‰ê·  ê°€ê²© ê³„ì‚°í•˜ì—¬ ì •ë ¬\n",
                "engine_order = subset_engine.groupby('engine')['price'].mean().sort_values(ascending=False).index\n",
                "\n",
                "plt.figure(figsize=(15, 10))\n",
                "\n",
                "# 1. ì—”ì§„ë³„ í¸ì°¨ì™€ í‰ê· ì„ í•œëˆˆì— ë³´ê¸° ìœ„í•œ Boxplot Drawing\n",
                "sns.boxplot(\n",
                "    y='engine', \n",
                "    x='price', \n",
                "    data=subset_engine, \n",
                "    order=engine_order, \n",
                "    palette='viridis'\n",
                ")\n",
                "\n",
                "plt.xscale('log') # ê°€ê²© ë²”ìœ„ê°€ ë„“ìœ¼ë¯€ë¡œ ë¡œê·¸ ìŠ¤ì¼€ì¼ ì ìš©\n",
                "plt.title('Price Distribution by Top 20 Most Common Engines', fontsize=18)\n",
                "plt.xlabel('Price ($) - Log Scale', fontsize=14)\n",
                "plt.ylabel('Engine Type', fontsize=14)\n",
                "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# (ì„ íƒ) í‰ê·  ê°€ê²© í‘œì‹œë¥¼ ìœ„í•œ Bar Plot ì¶”ê°€\n",
                "plt.figure(figsize=(15, 10))\n",
                "sns.barplot(\n",
                "    y='engine', \n",
                "    x='price', \n",
                "    data=subset_engine, \n",
                "    order=engine_order, \n",
                "    palette='viridis', \n",
                "    errorbar=None\n",
                ")\n",
                "\n",
                "plt.title('Average Price by Top 20 Most Common Engines', fontsize=18)\n",
                "plt.xlabel('Average Price ($)', fontsize=14)\n",
                "plt.ylabel('Engine Type', fontsize=14)\n",
                "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
                "\n",
                "# ë§‰ëŒ€ ëì— ê°’ í‘œì‹œ\n",
                "for i, p in enumerate(plt.gca().patches):\n",
                "    width = p.get_width()\n",
                "    plt.gca().text(width + 1000, p.get_y() + p.get_height() / 2, \n",
                "             f'${int(width):,}', va='center', fontsize=10)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import re\n",
                "\n",
                "def preprocess_car_data(df, is_train=True):\n",
                "    # ì›ë³¸ ë³´í˜¸ë¥¼ ìœ„í•´ ë³µì‚¬\n",
                "    df = df.copy()\n",
                "    \n",
                "    # ---------------------------------------------------------\n",
                "    # 1. ê¸°ë³¸ ë¶ˆí•„ìš” ì»¬ëŸ¼ ì œê±° & ê²°ì¸¡ì¹˜ ì „ëµ (Clean Title, Accident)\n",
                "    # ---------------------------------------------------------\n",
                "    if 'id' in df.columns:\n",
                "        df = df.drop('id', axis=1)\n",
                "        \n",
                "    # 'No'ì™€ 'Unknown'ìœ¼ë¡œ ì±„ì›Œì„œ ë¹„ì‹¼ ì°¨/íŠ¹ìˆ˜ ì°¨ êµ¬ë¶„í•˜ê¸°\n",
                "    df['clean_title'] = df['clean_title'].fillna('No')\n",
                "    df['accident'] = df['accident'].fillna('Unknown')\n",
                "    \n",
                "    # ---------------------------------------------------------\n",
                "    # 2. ì—°ì‹ ë³´ì • (2024ë…„ -> 2023ë…„ í†µí•©)\n",
                "    # ---------------------------------------------------------\n",
                "    df.loc[df['model_year'] == 2024, 'model_year'] = 2023\n",
                "    \n",
                "    # ì°¨ëŸ‰ ë‚˜ì´ íŒŒìƒë³€ìˆ˜\n",
                "    df['car_age'] = 2026 - df['model_year']\n",
                "\n",
                "    # ---------------------------------------------------------\n",
                "    # 3. [í•µì‹¬] ì—”ì§„ ì •ë³´ ì •ë°€ ì¶”ì¶œ (ì—…ê·¸ë ˆì´ë“œ ë²„ì „!)\n",
                "    # ---------------------------------------------------------\n",
                "    # (1) ë°°ê¸°ëŸ‰ (L): \"L\"ê³¼ \"Liter\" ëª¨ë‘ ì¡ê¸°\n",
                "    df['liter'] = df['engine'].str.extract(r'(\\d+\\.?\\d*)\\s*(?:L|Liter)').astype(float)\n",
                "    \n",
                "    # (2) ê¸°í†µ ìˆ˜: \"Cylinder\"ì™€ \"V6/I4\" íŒ¨í„´ ëª¨ë‘ ì¡ê¸°\n",
                "    cyl_std = df['engine'].str.extract(r'(\\d+)\\s*Cylinder').astype(float)\n",
                "    cyl_v = df['engine'].str.extract(r'(?:V|I|H|W)(\\d+)').astype(float)\n",
                "    df['cylinder'] = cyl_std.fillna(cyl_v) # ë‘˜ ì¤‘ í•˜ë‚˜ë¼ë„ ê±¸ë¦¬ë©´ ì„±ê³µ\n",
                "    \n",
                "    # (3) ë§ˆë ¥ (HP): ìˆ«ì+HP ì¶”ì¶œ\n",
                "    df['hp'] = df['engine'].str.extract(r'(\\d+\\.?\\d*)HP').astype(float)\n",
                "    \n",
                "    # ---------------------------------------------------------\n",
                "    # 4. ê²°ì¸¡ì¹˜ ì‹¬íì†Œìƒìˆ  (Smart Imputation)\n",
                "    # ---------------------------------------------------------\n",
                "    # (1) ì „ê¸°ì°¨ëŠ” ë°°ê¸°ëŸ‰ 0.0ìœ¼ë¡œ ì„¤ì •\n",
                "    ev_mask = (df['fuel_type'] == 'Electric') | df['engine'].str.contains('Electric', case=False, na=False)\n",
                "    df.loc[ev_mask, 'liter'] = df.loc[ev_mask, 'liter'].fillna(0.0)\n",
                "    \n",
                "    # (2) ë§ˆë ¥(HP)ì´ ë¹„ì–´ìˆìœ¼ë©´? -> 'ê¸°í†µ ìˆ˜'ì— ë§ëŠ” ì¤‘ìœ„ê°’ìœ¼ë¡œ ì±„ìš°ê¸°!\n",
                "    # (ì£¼ì˜: í•™ìŠµìš© ë°ì´í„°ì—ì„œ ê³„ì‚°í•œ mapì„ í…ŒìŠ¤íŠ¸ì—ë„ ì¨ì•¼ ì •ì„ì´ì§€ë§Œ, ì—¬ê¸°ì„  í¸ì˜ìƒ ê°ì ê³„ì‚°)\n",
                "    hp_map = df.groupby('cylinder')['hp'].median().to_dict()\n",
                "    df['hp'] = df['hp'].fillna(df['cylinder'].map(hp_map))\n",
                "    \n",
                "    # ê·¸ë˜ë„ ë¹„ì–´ìˆìœ¼ë©´ ì „ì²´ ì¤‘ìœ„ê°’\n",
                "    df['hp'] = df['hp'].fillna(df['hp'].median())\n",
                "    df['liter'] = df['liter'].fillna(df['liter'].median())\n",
                "    df['cylinder'] = df['cylinder'].fillna(df['cylinder'].median())\n",
                "\n",
                "    # ---------------------------------------------------------\n",
                "    # 5. (ì„ íƒ) ë³€ì†ê¸° ê¸°ì–´ ë‹¨ìˆ˜ ì¶”ì¶œ\n",
                "    # ---------------------------------------------------------\n",
                "    df['gear_count'] = df['transmission'].str.extract(r'(\\d+)-Speed').astype(float)\n",
                "    df['gear_count'] = df['gear_count'].fillna(df['gear_count'].mode()[0])\n",
                "\n",
                "    return df"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **transmission**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ê°€ì¥ ë§ì´ ë“±ì¥í•˜ëŠ” Transmission ìƒìœ„ 15ê°œ ì¶”ì¶œ\n",
                "top_15_transmission = train['transmission'].value_counts().head(15).index\n",
                "\n",
                "# í•´ë‹¹ ë°ì´í„°ë§Œ í•„í„°ë§\n",
                "subset_transmission = train[train['transmission'].isin(top_15_transmission)]\n",
                "\n",
                "# í‰ê·  ê°€ê²© ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬\n",
                "transmission_order = subset_transmission.groupby('transmission')['price'].mean().sort_values(ascending=False).index\n",
                "\n",
                "plt.figure(figsize=(16, 8))\n",
                "\n",
                "# 1. Boxplot (Log Scale) - ê°€ê²© ë¶„í¬ í™•ì¸\n",
                "sns.boxplot(\n",
                "    x='transmission', \n",
                "    y='price', \n",
                "    data=subset_transmission, \n",
                "    order=transmission_order, \n",
                "    palette='coolwarm'\n",
                ")\n",
                "\n",
                "plt.title('Price Distribution by Top 15 Transmission Types', fontsize=18)\n",
                "plt.ylabel('Price ($) - Log Scale', fontsize=14)\n",
                "plt.xlabel('Transmission Type', fontsize=14)\n",
                "plt.xticks(rotation=45, ha='right', fontsize=11)\n",
                "plt.yscale('log') # ê°€ê²© ë²”ìœ„ê°€ ë„“ìœ¼ë¯€ë¡œ ë¡œê·¸ ìŠ¤ì¼€ì¼ ì ìš©\n",
                "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# 2. Bar Plot - í‰ê·  ê°€ê²© ë¹„êµ\n",
                "plt.figure(figsize=(16, 8))\n",
                "sns.barplot(\n",
                "    x='transmission', \n",
                "    y='price', \n",
                "    data=subset_transmission, \n",
                "    order=transmission_order, \n",
                "    palette='coolwarm', \n",
                "    errorbar=None\n",
                ")\n",
                "\n",
                "plt.title('Average Price by Top 15 Transmission Types', fontsize=18)\n",
                "plt.ylabel('Average Price ($)', fontsize=14)\n",
                "plt.xlabel('Transmission Type', fontsize=14)\n",
                "plt.xticks(rotation=45, ha='right', fontsize=11)\n",
                "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
                "\n",
                "# ê°’ í‘œì‹œ\n",
                "for p in plt.gca().patches:\n",
                "    height = p.get_height()\n",
                "    plt.gca().text(p.get_x() + p.get_width() / 2, height + 1000, \n",
                "             f'${int(height):,}', ha='center', fontsize=10, rotation=45)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def clean_transmission(x):\n",
                "    x = str(x).lower()\n",
                "    if 'cvt' in x:\n",
                "        return 'CVT'\n",
                "    elif 'manual' in x or 'm/t' in x:\n",
                "        return 'Manual'\n",
                "    elif 'dual shift' in x or 'dct' in x:\n",
                "        return 'DCT'  # ë“€ì–¼ í´ëŸ¬ì¹˜\n",
                "    elif 'automatic' in x or 'a/t' in x:\n",
                "        return 'Automatic'\n",
                "    else:\n",
                "        return 'Other'\n",
                "\n",
                "# ìƒˆë¡œìš´ ì»¬ëŸ¼ ìƒì„±\n",
                "train['transmission_simple'] = train['transmission'].apply(clean_transmission)\n",
                "\n",
                "# ê²°ê³¼ í™•ì¸\n",
                "print(train['transmission_simple'].value_counts())\n",
                "\n",
                "# ì‹œê°í™”ë¡œ ë¹„êµ\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.boxplot(x='transmission_simple', y='price', data=train, palette='coolwarm')\n",
                "plt.yscale('log')\n",
                "plt.title('Price Distribution by Simplified Transmission')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. (ì‚¬ìš©ìë‹˜ì´ ì§  ì½”ë“œ) ë¨¼ì € transmission_simple ë§Œë“¤ê¸°\n",
                "def clean_transmission(x):\n",
                "    x = str(x).lower()\n",
                "    if 'cvt' in x:\n",
                "        return 'CVT'\n",
                "    elif 'manual' in x or 'm/t' in x:\n",
                "        return 'Manual'\n",
                "    elif 'dual shift' in x or 'dct' in x:\n",
                "        return 'DCT'\n",
                "    elif 'automatic' in x or 'a/t' in x:\n",
                "        return 'Automatic'\n",
                "    else:\n",
                "        return 'Other'\n",
                "\n",
                "train['transmission_simple'] = train['transmission'].apply(clean_transmission)\n",
                "\n",
                "# ---------------------------------------------------------\n",
                "# 2. [í•µì‹¬] Target Encoding (ê°€ê²© ì¤‘ìœ„ê°’ìœ¼ë¡œ ë³€í™˜)\n",
                "# ---------------------------------------------------------\n",
                "# ê° ë³€ì†ê¸° íƒ€ì…ë³„ë¡œ ì¤‘ìœ„ ê°€ê²© ê³„ì‚° (ì˜ˆ: DCTëŠ” ë¹„ì‹¸ë‹ˆê¹Œ ë†’ì€ ìˆ«ì)\n",
                "transmission_map = train.groupby('transmission_simple')['price'].median()\n",
                "\n",
                "# ê³„ì‚°ëœ ê°’ì„ ìƒˆ ì»¬ëŸ¼ì— ë§¤í•‘\n",
                "train['transmission_encoded'] = train['transmission_simple'].map(transmission_map)\n",
                "\n",
                "# (í˜¹ì‹œ ëª¨ë¥¼ ê²°ì¸¡ì¹˜ ì•ˆì „ì¥ì¹˜)\n",
                "train['transmission_encoded'] = train['transmission_encoded'].fillna(train['price'].median())\n",
                "\n",
                "# 3. í™•ì¸\n",
                "print(\"âœ… ë³€ì†ê¸° ì¸ì½”ë”© ì™„ë£Œ!\")\n",
                "print(train[['transmission_simple', 'transmission_encoded']].value_counts().head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **ext_col, int_col**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# í•¨ìˆ˜ ì •ì˜: Top 10 ì™¸ì—ëŠ” 'Other'ë¡œ ë³€ê²½\n",
                "def categorize_top_n(series, n=10, other_label='Other'):\n",
                "    top_n = series.value_counts().head(n).index\n",
                "    return series.apply(lambda x: x if x in top_n else other_label)\n",
                "\n",
                "# 1. ext_col (ì™¸ì¥ ìƒ‰ìƒ) ì²˜ë¦¬\n",
                "train['ext_col_categorized'] = categorize_top_n(train['ext_col'], n=10)\n",
                "\n",
                "# 2. int_col (ë‚´ì¥ ìƒ‰ìƒ) ì²˜ë¦¬\n",
                "train['int_col_categorized'] = categorize_top_n(train['int_col'], n=10)\n",
                "\n",
                "# ì‹œê°í™”í•  ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸\n",
                "color_cols = ['ext_col_categorized', 'int_col_categorized']\n",
                "titles = ['Exterior Color Price Distribution', 'Interior Color Price Distribution']\n",
                "\n",
                "plt.figure(figsize=(18, 12))\n",
                "\n",
                "for i, col in enumerate(color_cols):\n",
                "    plt.subplot(2, 1, i + 1)\n",
                "    \n",
                "    # í‰ê·  ê°€ê²© ìˆœìœ¼ë¡œ ì •ë ¬\n",
                "    order = train.groupby(col)['price'].median().sort_values(ascending=False).index\n",
                "    \n",
                "    sns.boxplot(x=col, y='price', data=train, order=order, palette='viridis')\n",
                "    \n",
                "    plt.title(titles[i], fontsize=16)\n",
                "    plt.xlabel('Color', fontsize=12)\n",
                "    plt.ylabel('Price ($) - Log Scale', fontsize=12)\n",
                "    plt.yscale('log') # ê°€ê²© ë²”ìœ„ê°€ ë„“ìœ¼ë¯€ë¡œ ë¡œê·¸ ìŠ¤ì¼€ì¼ ì ìš©\n",
                "    plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# (ì°¸ê³ ) ê° ìƒ‰ìƒë³„ ê°œìˆ˜ ì¶œë ¥\n",
                "print(\"\\n[ Exterior Color Counts ]\")\n",
                "print(train['ext_col_categorized'].value_counts())\n",
                "print(\"\\n[ Interior Color Counts ]\")\n",
                "print(train['int_col_categorized'].value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. (ì‚¬ìš©ìë‹˜ì˜ í•¨ìˆ˜) Top 10 ì™¸ì—ëŠ” 'Other'ë¡œ ë¬¶ê¸°\n",
                "def categorize_top_n(series, n=10, other_label='Other'):\n",
                "    top_n = series.value_counts().head(n).index\n",
                "    return series.apply(lambda x: x if x in top_n else other_label)\n",
                "\n",
                "# 2. ìƒ‰ìƒ ì»¬ëŸ¼ ë‹¨ìˆœí™” (Categorization)\n",
                "train['ext_col_simple'] = categorize_top_n(train['ext_col'], n=10)\n",
                "train['int_col_simple'] = categorize_top_n(train['int_col'], n=10)\n",
                "\n",
                "# ---------------------------------------------------------\n",
                "# 3. [í•µì‹¬] Target Encoding (ê°€ê²© ì¤‘ìœ„ê°’ìœ¼ë¡œ ë³€í™˜)\n",
                "# ---------------------------------------------------------\n",
                "# (1) ì™¸ì¥ ìƒ‰ìƒ (Exterior) ì¸ì½”ë”©\n",
                "ext_map = train.groupby('ext_col_simple')['price'].median()\n",
                "train['ext_col_encoded'] = train['ext_col_simple'].map(ext_map)\n",
                "\n",
                "# (2) ë‚´ì¥ ìƒ‰ìƒ (Interior) ì¸ì½”ë”©\n",
                "int_map = train.groupby('int_col_simple')['price'].median()\n",
                "train['int_col_encoded'] = train['int_col_simple'].map(int_map)\n",
                "\n",
                "# (3) ê²°ì¸¡ì¹˜ ì•ˆì „ì¥ì¹˜\n",
                "train['ext_col_encoded'] = train['ext_col_encoded'].fillna(train['price'].median())\n",
                "train['int_col_encoded'] = train['int_col_encoded'].fillna(train['price'].median())\n",
                "\n",
                "# 4. ê²°ê³¼ í™•ì¸\n",
                "print(\"âœ… ìƒ‰ìƒ ì¸ì½”ë”© ì™„ë£Œ!\")\n",
                "print(train[['ext_col_simple', 'ext_col_encoded']].value_counts().head())\n",
                "print(train[['int_col_simple', 'int_col_encoded']].value_counts().head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **clean_title**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ê²°ì¸¡ì¹˜ë¥¼ 'No'ë¼ëŠ” ë¬¸ìì—´ë¡œ ì±„ì›ë‹ˆë‹¤.\n",
                "train['clean_title'] = train['clean_title'].fillna('No')\n",
                "test['clean_title'] = test['clean_title'].fillna('No') # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë„ ë˜‘ê°™ì´!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **accident_filled**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (NaN -> 'Unknown')\n",
                "train['accident_filled'] = train['accident'].fillna('Unknown')\n",
                "\n",
                "# ì‚¬ê³  ì´ë ¥ë³„ ê°€ê²© ë¹„êµ ì‹œê°í™”\n",
                "plt.figure(figsize=(16, 6))\n",
                "\n",
                "# 1. Boxplot (Log Scale) - ê°€ê²© ë¶„í¬ ë¹„êµ\n",
                "plt.subplot(1, 2, 1)\n",
                "sns.boxplot(x='accident_filled', y='price', data=train, palette='coolwarm')\n",
                "plt.title('Price Distribution by Accident History (Log Scale)')\n",
                "plt.ylabel('Price ($) - Log Scale')\n",
                "plt.xlabel('Accident History')\n",
                "plt.yscale('log') # ê°€ê²© ì°¨ì´ê°€ í´ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë¡œê·¸ ìŠ¤ì¼€ì¼ ì ìš©\n",
                "\n",
                "# 2. Barplot - í‰ê·  ê°€ê²© ë¹„êµ\n",
                "plt.subplot(1, 2, 2)\n",
                "sns.barplot(x='accident_filled', y='price', data=train, estimator=np.mean, errorbar=None, palette='coolwarm')\n",
                "plt.title('Average Price by Accident History')\n",
                "plt.ylabel('Average Price ($)')\n",
                "plt.xlabel('Accident History')\n",
                "\n",
                "# í‰ê·  ê°€ê²© í…ìŠ¤íŠ¸ í‘œì‹œ\n",
                "for p in plt.gca().patches:\n",
                "    height = p.get_height()\n",
                "    plt.gca().text(p.get_x() + p.get_width() / 2, height + 500, \n",
                "             f'${int(height):,}', ha='center', fontsize=10)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **model year**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(15, 6))\n",
                "\n",
                "# 1. Line Plot (Price Trend by Year) - ì—°ì‹ë³„ í‰ê·  ê°€ê²© ì¶”ì„¸\n",
                "sns.lineplot(x='model_year', y='price', data=train, color='royalblue', label='Average Price')\n",
                "plt.title('Average Price Trend by Model Year', fontsize=16)\n",
                "plt.ylabel('Average Price ($)', fontsize=12)\n",
                "plt.xlabel('Model Year', fontsize=12)\n",
                "plt.grid(True)\n",
                "plt.legend()\n",
                "plt.show()\n",
                "\n",
                "# 2. Boxplot (Price Distribution by Year) - ì—°ë„ë³„ ê°€ê²© ë¶„í¬ í™•ì¸\n",
                "plt.figure(figsize=(18, 8))\n",
                "sns.boxplot(x='model_year', y='price', data=train, palette='viridis')\n",
                "plt.title('Price Distribution by Model Year (Boxplot)', fontsize=16)\n",
                "plt.ylabel('Price ($) - Log Scale', fontsize=12) # ê°€ê²©ì°¨ê°€ ì»¤ì„œ ë¡œê·¸ ë³€í™˜ ì ìš©\n",
                "plt.xlabel('Model Year', fontsize=12)\n",
                "plt.yscale('log') # Yì¶• ë¡œê·¸ ìŠ¤ì¼€ì¼ ì ìš©\n",
                "plt.xticks(rotation=45) # ì—°ë„ê°€ ê²¹ì¹˜ì§€ ì•Šê²Œ íšŒì „\n",
                "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. ì°¨ëŸ‰ ë‚˜ì´ (ì˜¬í•´ - ì—°ì‹)\n",
                "train['car_age'] = 2026 - train['model_year']\n",
                "test['car_age'] = 2026 - test['model_year']\n",
                "\n",
                "# 2. ì—°ê°„ ì£¼í–‰ê±°ë¦¬ (í˜¹ì‚¬ ì ìˆ˜)\n",
                "# 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ car_ageê°€ 0ì´ë©´ 1ë¡œ ì‚´ì§ ë³´ì •\n",
                "train['miles_per_year'] = train['milage'] / train['car_age'].replace(0, 1)\n",
                "test['miles_per_year'] = test['milage'] / test['car_age'].replace(0, 1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **ê°€ê²© ì´ìƒì¹˜ ì œê±°**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. ì´ìƒì¹˜ ê¸°ì¤€ ì„¤ì • (ìƒìœ„ 0.1%)\n",
                "threshold = train['price'].quantile(0.999)\n",
                "print(f\"ğŸš¨ ì´ìƒì¹˜ ì»¤íŠ¸ë¼ì¸ (ìƒìœ„ 0.1%): ${threshold:,.0f} ì´ìƒ\")\n",
                "\n",
                "# 3. ì´ìƒì¹˜ ë°ì´í„° ì¶”ì¶œ (í‘œë¡œ í™•ì¸í•˜ê¸° ìœ„í•¨)\n",
                "outliers = train[train['price'] > threshold].sort_values('price', ascending=False)\n",
                "\n",
                "print(f\"\\n=== [ê²½ê³ ] ì‚­ì œ ëŒ€ìƒ ì´ìƒì¹˜ ëª©ë¡ (ì´ {len(outliers)}ê°œ) ===\")\n",
                "# ê°€ë…ì„±ì„ ìœ„í•´ ì£¼ìš” ì»¬ëŸ¼ë§Œ ì¶œë ¥\n",
                "print(outliers[['brand', 'model', 'model_year', 'price']].head(10))\n",
                "\n",
                "# 4. ì‹œê°í™” (í•œëˆˆì— í™•ì¸í•˜ê¸°)\n",
                "plt.figure(figsize=(15, 6))\n",
                "\n",
                "# (1) ê°€ê²© ë¶„í¬ íˆìŠ¤í† ê·¸ë¨ (ë¡œê·¸ ìŠ¤ì¼€ì¼)\n",
                "plt.subplot(1, 2, 1)\n",
                "sns.histplot(train['price'], bins=50, log_scale=True, color='skyblue')\n",
                "plt.axvline(threshold, color='red', linestyle='--', label=f'Threshold (${threshold:,.0f})')\n",
                "plt.title('Price Distribution (Log Scale)')\n",
                "plt.xlabel('Price ($)')\n",
                "plt.legend()\n",
                "\n",
                "# (2) ì—°ì‹ë³„ ê°€ê²© ì‚°ì ë„ (ì´ìƒì¹˜ê°€ ì–¼ë§ˆë‚˜ íŠ€ëŠ”ì§€ í™•ì¸)\n",
                "plt.subplot(1, 2, 2)\n",
                "sns.scatterplot(x='model_year', y='price', data=train, alpha=0.3, label='Normal')\n",
                "# ì´ìƒì¹˜ë§Œ ë¹¨ê°„ìƒ‰ìœ¼ë¡œ í‘œì‹œ\n",
                "sns.scatterplot(x='model_year', y='price', data=outliers, color='red', s=50, label='Outliers')\n",
                "plt.yscale('log') # ë¡œê·¸ ìŠ¤ì¼€ì¼ë¡œ ë´ì•¼ ì˜ ë³´ì„\n",
                "plt.title('Price by Year (Red = Outliers)')\n",
                "plt.xlabel('Model Year')\n",
                "plt.ylabel('Price ($)')\n",
                "plt.legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show() # ê·¸ë˜í”„ ì¶œë ¥\n",
                "\n",
                "# 5. (ì„ íƒ) ì´ìƒì¹˜ ì œê±° í›„ ë°ì´í„° ë¶„í¬ í™•ì¸\n",
                "print(\"\\n=== [ì°¸ê³ ] ì´ìƒì¹˜ ì œê±° ì‹œ ì˜ˆìƒë˜ëŠ” ë°ì´í„° ë¶„í¬ ===\")\n",
                "clean_data = train[train['price'] <= threshold]\n",
                "print(clean_data['price'].describe())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **ì¤‘ë³µ ë°ì´í„° ì œê±°**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. ê°€ì§œ ë¶€ì ë°ì´í„° ë‹¤ì‹œ ì¶”ì¶œ\n",
                "threshold = train['price'].quantile(0.999)\n",
                "all_outliers = train[train['price'] >= threshold]\n",
                "supercar_brands = ['Bugatti', 'Ferrari', 'Lamborghini', 'Rolls-Royce', 'McLaren', 'Bentley', 'Aston', 'Maybach','Porsche']\n",
                "fake_rich_cars = all_outliers[~all_outliers['brand'].isin(supercar_brands)]\n",
                "\n",
                "# 3. ê°€ê²©ë³„ ê°œìˆ˜ ì„¸ê¸° (Top 10)\n",
                "price_counts = fake_rich_cars['price'].value_counts().reset_index()\n",
                "price_counts.columns = ['Price ($)', 'Count']\n",
                "\n",
                "# 4. ê° ê°€ê²©ë³„ ëŒ€í‘œ ì°¨ì¢…(Brand + Model) ì˜ˆì‹œ ì¶”ê°€\n",
                "examples = []\n",
                "for price in price_counts['Price ($)']:\n",
                "    # í•´ë‹¹ ê°€ê²©ì„ ê°€ì§„ ì°¨ë“¤ì˜ ë¸Œëœë“œ+ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ (ì¤‘ë³µ ì œê±°, ìƒìœ„ 3ê°œë§Œ)\n",
                "    sample_cars = fake_rich_cars[fake_rich_cars['price'] == price]\n",
                "    car_list = (sample_cars['brand'] + \" \" + sample_cars['model']).unique()[:3]\n",
                "    examples.append(\", \".join(car_list))\n",
                "\n",
                "price_counts['Examples (Top 3)'] = examples\n",
                "\n",
                "# 5. ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥\n",
                "print(f\"=== [ì¶©ê²©] ì‚­ì œëœ ê°€ì§œ ê°€ê²©í‘œ TOP {len(price_counts)} ===\")\n",
                "# ì²œ ë‹¨ìœ„ ì½¤ë§ˆ í¬ë§·íŒ… ì ìš©í•´ì„œ ë³´ì—¬ì£¼ê¸°\n",
                "pd.options.display.float_format = '{:,.0f}'.format\n",
                "print(price_counts)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **ê°€ì§œ ë¶€ì ì‚­ì œ**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. ìŠˆí¼ì¹´ ë¸Œëœë“œ ë¦¬ìŠ¤íŠ¸ ì •ì˜ (ì´ ë¸Œëœë“œë“¤ì€ ë¹„ì‹¸ë„ ë´ì¤Œ)\n",
                "supercar_brands = ['Bugatti', 'Ferrari', 'Lamborghini', 'Rolls-Royce', 'McLaren', 'Bentley', 'Aston', 'Maybach','Porsche']\n",
                "\n",
                "# 2. ì´ìƒì¹˜ ì œê±° ì¡°ê±´ ì„¤ì •\n",
                "# (1) ê°€ê²©ì´ 70ë§Œ ë¶ˆ($700,000) ì´ìƒì´ë©´ì„œ\n",
                "# (2) ìŠˆí¼ì¹´ ë¸Œëœë“œê°€ ì•„ë‹Œ ê²½ìš° -> \"ë„ˆ, ê°€ì§œì§€?\" í•˜ê³  ì‚­ì œ\n",
                "fake_rich_mask = (train['price'] > 700000) & (~train['brand'].isin(supercar_brands))\n",
                "\n",
                "# 3. ì§„ì§œ ì´ìƒì¹˜ë§Œ ê³¨ë¼ë‚´ì„œ ì‚­ì œ\n",
                "train_smart_clean = train[~fake_rich_mask].copy()\n",
                "\n",
                "# 4. ê²°ê³¼ í™•ì¸\n",
                "deleted_count = fake_rich_mask.sum()\n",
                "print(f\"ğŸ•µï¸â€â™‚ï¸ ìŠ¤ë§ˆíŠ¸ í•„í„°ë§ ê²°ê³¼: ì´ {deleted_count}ê°œì˜ 'ê°€ì§œ ë¶€ì' ë°ì´í„°ë§Œ ì‚­ì œí–ˆìŠµë‹ˆë‹¤!\")\n",
                "print(f\"ë‚¨ì€ ë°ì´í„° ê°œìˆ˜: {len(train_smart_clean)}\")\n",
                "\n",
                "# ì‚­ì œëœ ë†ˆë“¤ êµ¬ê²½í•˜ê¸° (í˜„ëŒ€, í¬ë“œ ë“±ì´ ì¡í˜€ìˆì–´ì•¼ í•¨)\n",
                "print(\"\\n=== [ì‚­ì œëœ ê°€ì§œ ë°ì´í„° ì˜ˆì‹œ] ===\")\n",
                "print(train[fake_rich_mask][['brand', 'model', 'price']].head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ---------------------------------------------------------\n",
                "# Case 1: \"ìµœì‹  ì°¨ê°€ ì™œ ì´ë ‡ê²Œ ì‹¸?\" (2020ë…„ ì´í›„, $10,000 ë¯¸ë§Œ)\n",
                "# ---------------------------------------------------------\n",
                "suspicious_new_cars = train[\n",
                "    (train['model_year'] >= 2020) & \n",
                "    (train['price'] < 10000)\n",
                "].sort_values('price')\n",
                "\n",
                "print(f\"=== [ì˜ì‹¬] 2020ë…„ ì´í›„ì¸ë° $10,000 ë¯¸ë§Œì¸ ì°¨: {len(suspicious_new_cars)}ëŒ€ ===\")\n",
                "print(suspicious_new_cars[['brand', 'model', 'model_year', 'price']].head(10))\n",
                "\n",
                "\n",
                "# ---------------------------------------------------------\n",
                "# Case 2: \"ìŠˆí¼ì¹´ê°€ ì•„ë°˜ë–¼ ê°€ê²©?\" (ìŠˆí¼ì¹´ ë¸Œëœë“œ, $30,000 ë¯¸ë§Œ)\n",
                "# ---------------------------------------------------------\n",
                "supercar_brands = ['Bugatti', 'Ferrari', 'Lamborghini', 'Rolls-Royce', 'McLaren', 'Bentley', 'Aston', 'Maybach']\n",
                "\n",
                "suspicious_supercars = train[\n",
                "    (train['brand'].isin(supercar_brands)) & \n",
                "    (train['price'] < 30000) # 3ë§Œë¶ˆ ë¯¸ë§Œì´ë©´ ì˜ì‹¬\n",
                "].sort_values('price')\n",
                "\n",
                "print(f\"\\n=== [ì˜ì‹¬] ìŠˆí¼ì¹´ ë¸Œëœë“œì¸ë° $30,000 ë¯¸ë§Œì¸ ì°¨: {len(suspicious_supercars)}ëŒ€ ===\")\n",
                "print(suspicious_supercars[['brand', 'model', 'model_year', 'price']].head(10))\n",
                "\n",
                "\n",
                "# ---------------------------------------------------------\n",
                "# Case 3: ì „ì²´ ìµœì €ê°€ TOP 10 êµ¬ê²½í•˜ê¸° (ë„ˆë¬´ ì‹¼ ì°¨ ì‹ë³„ìš©)\n",
                "# ---------------------------------------------------------\n",
                "print(\"\\n=== [ì°¸ê³ ] ë°ì´í„°ì…‹ ì „ì²´ ìµœì €ê°€ TOP 10 ===\")\n",
                "print(train.sort_values('price')[['brand', 'model', 'model_year', 'price']].head(10))\n",
                "\n",
                "\n",
                "# =========================================================\n",
                "# ğŸš¨ [ì¶”ê°€ëœ ì½”ë“œ] í™•ì¸ë§Œ í•˜ì§€ ë§ê³  ì§„ì§œ ì‚­ì œí•˜ì!\n",
                "# =========================================================\n",
                "\n",
                "# 1. ì‚­ì œí•  ë°ì´í„°ë“¤ì˜ 'ì£¼ë¯¼ë²ˆí˜¸(Index)'ë¥¼ ëª¨ë‘ ëª¨ìë‹ˆë‹¤.\n",
                "# (ìœ„ì—ì„œ ì°¾ì€ 'ìµœì‹  ë˜¥ì°¨' + 'ê°€ì§œ ìŠˆí¼ì¹´')\n",
                "drop_indices = suspicious_new_cars.index.union(suspicious_supercars.index)\n",
                "\n",
                "# 2. (ì¶”ê°€) ê·¸ëƒ¥ ê°€ê²©ì´ ë„ˆë¬´ ì‹¼ ì°¨($2,000 ë¯¸ë§Œ)ë„ ì‚­ì œ ëŒ€ìƒì— í¬í•¨\n",
                "# (íì°¨ ìˆ˜ì¤€ì´ë¼ í•™ìŠµì— ë°©í•´ë¨)\n",
                "trash_indices = train[train['price'] < 3000].index\n",
                "drop_indices = drop_indices.union(trash_indices)\n",
                "\n",
                "# 3. ì‹¤ì œ ì‚­ì œ ì‹¤í–‰\n",
                "print(f\"\\nğŸ”ª ì‚­ì œ ì‹¤í–‰ ì „ ë°ì´í„° ê°œìˆ˜: {len(train)}ê°œ\")\n",
                "print(f\"ğŸš¨ ì‚­ì œ ëŒ€ìƒ ê°œìˆ˜: {len(drop_indices)}ê°œ\")\n",
                "\n",
                "train = train.drop(drop_indices)\n",
                "train = train.reset_index(drop=True) # ì¸ë±ìŠ¤ ê¹”ë”í•˜ê²Œ ì •ë¦¬\n",
                "\n",
                "print(f\"âœ… ì‚­ì œ ì™„ë£Œ! ë‚¨ì€ ë°ì´í„° ê°œìˆ˜: {len(train)}ê°œ\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. ê³ ê¸‰ì°¨ ë¸Œëœë“œ ë¦¬ìŠ¤íŠ¸ ì •ì˜\n",
                "luxury_brands = ['Mercedes-Benz', 'BMW', 'Audi', 'Lexus', 'Porsche', 'Land', 'Jaguar', 'Bentley', 'Maserati','Ferrari','Lamborghini']\n",
                "\n",
                "# 2. [ì¡°ê±´] \n",
                "# (1) ê³ ê¸‰ì°¨ì¸ë° \n",
                "# (2) 2010ë…„ ì´í›„ ì—°ì‹ì´ê³  \n",
                "# (3) ê°€ê²©ì´ $5,000 ë¯¸ë§Œì¸ë°\n",
                "# (4) ì£¼í–‰ê±°ë¦¬ê°€ 10ë§Œ ë§ˆì¼(ì•½ 16ë§Œ km) ë¯¸ë§Œì´ë‹¤? \n",
                "# -> \"ì´ê±´ ë§ë„ ì•ˆ ë¼! ë‚šì‹œë‹¤!\" (ì¡°ê±´ì‹)\n",
                "fake_luxury_mask = (\n",
                "    train['brand'].isin(luxury_brands) & \n",
                "    (train['model_year'] >= 2010) & \n",
                "    (train['price'] < 5000) &\n",
                "    (train['milage'] < 100000) # ì£¼í–‰ê±°ë¦¬ ì¡°ê±´ ì¶”ê°€!\n",
                ")\n",
                "\n",
                "# 3. ì‚­ì œ ëŒ€ìƒ í™•ì¸ (ì‚­ì œ ì „ì— ëˆˆìœ¼ë¡œ ê¼­ í™•ì¸!)\n",
                "suspicious_cars = train[fake_luxury_mask]\n",
                "print(f\"ğŸ•µï¸â€â™‚ï¸ [ì •ë°€ íƒ€ê²©] ìƒíƒœëŠ” ì¢‹ì€ë° ê°€ê²©ì´ ë§ì´ ì•ˆ ë˜ëŠ” ì°¨: {len(suspicious_cars)}ëŒ€\")\n",
                "\n",
                "# ì–´ë–¤ ë†ˆë“¤ì¸ì§€ êµ¬ê²½í•˜ê¸° (ë§ˆì¼ë¦¬ì§€ê°€ ì ì€ ìˆœì„œëŒ€ë¡œ)\n",
                "print(suspicious_cars[['brand', 'model', 'model_year', 'price', 'milage']].sort_values('milage').head(10))\n",
                "\n",
                "# 4. (í™•ì¸ í›„) ì‚­ì œ ì‹¤í–‰\n",
                "# ê¸°ì¡´ train ë³€ìˆ˜ì— ë®ì–´ì“°ê¸°\n",
                "train = train[~fake_luxury_mask].copy()\n",
                "print(f\"âœ… ì´ {len(suspicious_cars)}ê°œì˜ ë‚šì‹œ ë§¤ë¬¼ì„ ì‚­ì œí–ˆìŠµë‹ˆë‹¤!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ---------------------------------------------------------\n",
                "# 2. [í•µì‹¬] ê³¼ê°í•œ ì‚­ì œ (ì“°ë ˆê¸° 6,300ê°œ ì¦‰ê²° ì²˜í˜•)\n",
                "# ---------------------------------------------------------\n",
                "# (1) 400ë§Œì› ë¯¸ë§Œ ë˜¥ì°¨/ë‚šì‹œë§¤ë¬¼ ì‚­ì œ\n",
                "mask_junk = train['price'] < 4000\n",
                "\n",
                "# (2) 3000ë§Œì› ë¯¸ë§Œ ìŠˆí¼ì¹´(ì‚¬ê¸°) ì‚­ì œ\n",
                "luxury_brands = ['Lamborghini', 'Ferrari', 'McLaren', 'Rolls-Royce', 'Bentley', 'Aston', 'Porsche', 'Maserati']\n",
                "mask_luxury_scam = (train['brand'].isin(luxury_brands)) & (train['price'] < 30000)\n",
                "\n",
                "# (3) 10ì–µì› ì´ìƒ ì˜¤ë¥˜ ë°ì´í„° ì‚­ì œ\n",
                "mask_super_high = train['price'] > 1000000\n",
                "\n",
                "# (4) 2ì–µì› ì´ìƒ ì¼ë°˜ì°¨(ì˜¤ë¥˜) ì‚­ì œ\n",
                "common_brands = ['Ford', 'Toyota', 'Honda', 'Hyundai', 'Kia', 'Chevrolet', 'Nissan', 'Volkswagen']\n",
                "mask_common_error = (train['brand'].isin(common_brands)) & (train['price'] > 200000)\n",
                "\n",
                "# ì‚­ì œ ì‹¤í–‰\n",
                "drop_mask = mask_junk | mask_luxury_scam | mask_super_high | mask_common_error\n",
                "train = train[~drop_mask].reset_index(drop=True)\n",
                "\n",
                "print(f\"ğŸ§¹ ì²­ì†Œ ì™„ë£Œ! ì‚­ì œëœ ê°œìˆ˜: {drop_mask.sum()}ê°œ\")\n",
                "print(f\"âœ¨ ë‚¨ì€ ì •ì˜ˆ ë°ì´í„°: {len(train)}ê°œ (ì´ì œ ëª¨ë¸ì´ ê±´ê°•í•´ì¡ŒìŠµë‹ˆë‹¤!)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1990ë…„ ì´ì „ì„ 'Classic'ìœ¼ë¡œ ì •ì˜\n",
                "train['is_classic'] = (train['model_year'] < 1990).astype(int)\n",
                "test['is_classic'] = (test['model_year'] < 1990).astype(int)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2024ë…„ ë°ì´í„°ë¥¼ 2023ë…„ìœ¼ë¡œ í†µí•©í•˜ëŠ” ì½”ë“œ\n",
                "# (Trainê³¼ Test ëª¨ë‘ ì ìš©í•´ì•¼ í•©ë‹ˆë‹¤!)\n",
                "\n",
                "# 1. Train ë°ì´í„° ìˆ˜ì •\n",
                "train.loc[train['model_year'] == 2024, 'model_year'] = 2023\n",
                "\n",
                "# 2. Test ë°ì´í„° ìˆ˜ì •\n",
                "test.loc[test['model_year'] == 2024, 'model_year'] = 2023\n",
                "\n",
                "print(\"âœ… 2024ë…„ ë°ì´í„°ë¥¼ 2023ë…„ìœ¼ë¡œ í†µí•© ì™„ë£Œ!\")\n",
                "print(f\"ì´ì œ ê°€ì¥ ìµœì‹  ì—°ì‹ì€ {train['model_year'].max()}ë…„ ì…ë‹ˆë‹¤.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### í…ŒìŠ¤íŠ¸ì…‹ë„ ì´ìƒí•œì§€ í™•ì¸"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "# (ID ì»¬ëŸ¼ì´ ìˆë‹¤ë©´ ë°©í•´ë˜ë¯€ë¡œ ì œê±°í•˜ê³  ë¹„êµí•©ë‹ˆë‹¤)\n",
                "if 'id' in train.columns: train = train.drop('id', axis=1)\n",
                "if 'id' in test.columns: test = test.drop('id', axis=1)\n",
                "\n",
                "print(f\"Train ê°œìˆ˜: {len(train)}, Test ê°œìˆ˜: {len(test)}\")\n",
                "\n",
                "# ---------------------------------------------------------\n",
                "# 1. [í•µì‹¬] \"Trainì˜ ì´ìƒí•œ ë†ˆì´ Testì—ë„ ìˆëŠ”ê°€?\" (ë„í”Œê°±ì–´ ê²€ì‚¬)\n",
                "# ---------------------------------------------------------\n",
                "# Trainì—ì„œ ìš°ë¦¬ê°€ 'ì´ìƒí•˜ë‹¤'ê³  íŒëª…í–ˆë˜ ë°ì´í„°ë“¤ (40ì–µì§œë¦¬, ë‚šì‹œë§¤ë¬¼ ë“±)\n",
                "threshold_high = train['price'].quantile(0.999) # ìƒìœ„ 0.1% ê°€ê²©\n",
                "outliers_train = train[train['price'] > threshold_high]\n",
                "\n",
                "# Trainì˜ ì´ìƒì¹˜(ê°€ê²© ì œì™¸)ì™€ Test ë°ì´í„°ê°€ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸\n",
                "# (ë¸Œëœë“œ, ëª¨ë¸, ì—°ì‹, ì£¼í–‰ê±°ë¦¬, ìƒ‰ìƒ ë“±ì´ ëª¨ë‘ ë˜‘ê°™ì€ì§€)\n",
                "# ì£¼ì˜: priceëŠ” ë¹„êµ ëŒ€ìƒì—ì„œ ì œì™¸\n",
                "cols_to_compare = [col for col in test.columns if col != 'price']\n",
                "\n",
                "# êµì§‘í•© ì°¾ê¸° (Merge)\n",
                "leakage = pd.merge(outliers_train[cols_to_compare], test, on=cols_to_compare, how='inner')\n",
                "\n",
                "print(f\"\\nğŸ•µï¸â€â™‚ï¸ [ë„í”Œê°±ì–´ ê²€ì‚¬] Trainì˜ 'ì´ìƒì¹˜'ì™€ ë˜‘ê°™ì´ ìƒê¸´ ë†ˆì´ Testì— ìˆëŠ”ê°€?\")\n",
                "print(f\"ë°œê²¬ëœ ê°œìˆ˜: {len(leakage)}ê°œ\")\n",
                "\n",
                "if len(leakage) > 0:\n",
                "    print(\"ğŸš¨ ë¹„ìƒ! Trainì˜ ì´ìƒì¹˜ë¥¼ ì§€ìš°ë©´ ì•ˆ ë©ë‹ˆë‹¤! Testì—ë„ ë˜‘ê°™ì€ ë†ˆë“¤ì´ ìˆ¨ì–´ìˆìŠµë‹ˆë‹¤!\")\n",
                "    print(leakage.head())\n",
                "else:\n",
                "    print(\"âœ… ë‹¤í–‰íˆ Testì—ëŠ” Trainì˜ ì´ìƒì¹˜ì™€ ê²¹ì¹˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
                "\n",
                "# ---------------------------------------------------------\n",
                "# 2. [ìê°€ ë³µì œ] Test ì…‹ ì•ˆì—ì„œ ë˜‘ê°™ì€ê²Œ ë°˜ë³µë˜ëŠ”ê°€?\n",
                "# ---------------------------------------------------------\n",
                "test_duplicates = test.duplicated().sum()\n",
                "print(f\"\\nğŸ¤– [ìê°€ ë³µì œ ê²€ì‚¬] Test ì…‹ ì•ˆì— ë˜‘ê°™ì€ ë°ì´í„°ê°€ ë°˜ë³µë˜ëŠ”ê°€?\")\n",
                "print(f\"ì¤‘ë³µëœ í–‰ ê°œìˆ˜: {test_duplicates}ê°œ\")\n",
                "if test_duplicates > 0:\n",
                "    print(\"-> Test ì…‹ ìì²´ë„ í’ˆì§ˆì´ ì¢‹ì§€ ì•ŠìŠµë‹ˆë‹¤. (ì¤‘ë³µ ë°ì´í„° ì¡´ì¬)\")\n",
                "\n",
                "# ---------------------------------------------------------\n",
                "# 3. [ì¢€ë¹„ ì°¨] ë¬¼ë¦¬ì ìœ¼ë¡œ ë¶ˆê°€ëŠ¥í•œ ë°ì´í„° í™•ì¸\n",
                "# ---------------------------------------------------------\n",
                "# ì˜ˆ: 2010ë…„ ì´ì „ ì°¨ì¸ë° ì£¼í–‰ê±°ë¦¬ê°€ 100ë§ˆì¼ ë¯¸ë§Œ (ë°•ë¬¼ê´€ ì°¨ ì•„ë‹ˆë©´ ë¶ˆê°€ëŠ¥)\n",
                "zombie_cars = test[(test['model_year'] < 2010) & (test['milage'] < 100)]\n",
                "\n",
                "print(f\"\\nğŸ§Ÿ [ì¢€ë¹„ ì°¨ ê²€ì‚¬] ì˜¤ë˜ëœ ì—°ì‹(<2010)ì¸ë° ì£¼í–‰ê±°ë¦¬ê°€ ê±°ì˜ ì—†ëŠ”(<100mi) ì°¨?\")\n",
                "print(f\"ë°œê²¬ëœ ê°œìˆ˜: {len(zombie_cars)}ëŒ€\")\n",
                "if len(zombie_cars) > 0:\n",
                "    print(zombie_cars[['brand', 'model', 'model_year', 'milage']].head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==========================================\n",
                "# 2. [í•„ìˆ˜] ì´ìƒì¹˜ ì œê±° (Smart Cleaning)\n",
                "# ==========================================\n",
                "# (1) 'ê°€ì§œ ë¶€ì' (40ì–µ ì‹¼íƒ€í˜ ë“±) ì‚­ì œ\n",
                "supercar_brands = ['Bugatti', 'Ferrari', 'Lamborghini', 'Rolls-Royce', 'McLaren', 'Bentley', 'Aston', 'Maybach']\n",
                "fake_rich_mask = (train['price'] > 700000) & (~train['brand'].isin(supercar_brands))\n",
                "train = train[~fake_rich_mask].copy()\n",
                "\n",
                "# (2) 'ë‚šì‹œ ë§¤ë¬¼' (500ë§Œì› ë²¤ì¸  ë“±) ì‚­ì œ\n",
                "luxury_brands = ['Mercedes-Benz', 'BMW', 'Audi', 'Lexus', 'Porsche', 'Land', 'Jaguar', 'Bentley', 'Maserati']\n",
                "fake_cheap_mask = (\n",
                "    train['brand'].isin(luxury_brands) & \n",
                "    (train['model_year'] >= 2010) & \n",
                "    (train['milage'] < 100000) &\n",
                "    (train['price'] < 5000)\n",
                ")\n",
                "train = train[~fake_cheap_mask].copy()\n",
                "\n",
                "print(f\"âœ… ì´ìƒì¹˜ ì œê±° ì™„ë£Œ! ë‚¨ì€ ë°ì´í„° ê°œìˆ˜: {len(train)}ê°œ\")\n",
                "\n",
                "# ==========================================\n",
                "# 3. ìƒê´€ë¶„ì„ì„ ìœ„í•œ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (ìˆ«ìë¡œ ë³€í™˜)\n",
                "# ==========================================\n",
                "# (1) ë§ˆë ¥(HP) ì¶”ì¶œ: \"300.0HP\" -> 300.0 (ìˆ«ì)\n",
                "train['hp'] = train['engine'].str.extract(r'(\\d+\\.?\\d*)HP').astype(float)\n",
                "\n",
                "# (2) ì‚¬ê³  ìœ ë¬´: 'None' -> 0, 'Accident' -> 1\n",
                "train['accident_num'] = train['accident'].apply(lambda x: 0 if x == 'None reported' else 1)\n",
                "\n",
                "# (3) í´ë¦° íƒ€ì´í‹€: 'Yes' -> 1, 'No' -> 0\n",
                "train['clean_title_num'] = train['clean_title'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
                "\n",
                "# ==========================================\n",
                "# 4. íˆíŠ¸ë§µ ê·¸ë¦¬ê¸°\n",
                "# ==========================================\n",
                "plt.figure(figsize=(12, 10))\n",
                "\n",
                "# ìƒê´€ê³„ìˆ˜ ê³„ì‚° ëŒ€ìƒ ì»¬ëŸ¼ ì„ íƒ\n",
                "cols = ['price', 'model_year', 'milage', 'hp', 'accident_num', 'clean_title_num',\n",
                "'brand_encoded','model_encoded','fuel_type_encoded','transmission_encoded','ext_col_encoded','int_col_encoded']\n",
                "\n",
                "# ìƒê´€ê³„ìˆ˜ ê³„ì‚° (ê²°ì¸¡ì¹˜ ì œì™¸)\n",
                "corr_matrix = train[cols].corr()\n",
                "\n",
                "# íˆíŠ¸ë§µ ì¶œë ¥\n",
                "sns.heatmap(corr_matrix, \n",
                "            annot=True,       # ìˆ«ì í‘œì‹œ\n",
                "            fmt='.2f',        # ì†Œìˆ˜ì  2ìë¦¬\n",
                "            cmap='coolwarm',  # ë¹¨ê°•(ì–‘)-íŒŒë‘(ìŒ) ìƒ‰ìƒ\n",
                "            linewidths=0.5,   # ì¹¸ êµ¬ë¶„ì„ \n",
                "            vmin=-1, vmax=1)  # ìƒ‰ìƒ ë²”ìœ„ ê³ ì • (-1 ~ 1)\n",
                "\n",
                "plt.title('Correlation Matrix: Price vs Features (Clean Data)', fontsize=15)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **íŒŒìƒë³€ìˆ˜, ì „ì²˜ë¦¬ ì™„ë£Œì‘ì—…**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# ---------------------------------------------------------\n",
                "# 2. Test ë°ì´í„°ì—ë„ 'í•„ìˆ˜ íŒŒìƒë³€ìˆ˜' ìƒì„± (ì‚´ë ¤ì•¼ í•  ë†ˆë“¤)\n",
                "# ---------------------------------------------------------\n",
                "\n",
                "# (1) ì°¨ëŸ‰ ë‚˜ì´ & ì—°ê°„ ì£¼í–‰ê±°ë¦¬ (miles_per_year)\n",
                "test['car_age'] = 2026 - test['model_year']\n",
                "test['miles_per_year'] = test['milage'] / test['car_age'].replace(0, 1)\n",
                "\n",
                "# (2) í´ë˜ì‹ì¹´ ì—¬ë¶€ (is_classic)\n",
                "test['is_classic'] = (test['model_year'] < 1990).astype(int)\n",
                "\n",
                "# (3) ë§ˆë ¥ (HP) ì¶”ì¶œ ë° ê²°ì¸¡ì¹˜ ì±„ìš°ê¸°\n",
                "test['hp'] = test['engine'].str.extract(r'(\\d+\\.?\\d*)HP').astype(float)\n",
                "test['hp'] = test['hp'].fillna(train['hp'].median()) \n",
                "\n",
                "# (4) ì‚¬ê³  ìœ ë¬´ & í´ë¦° íƒ€ì´í‹€ (ìˆ«ìë¡œ ë³€í™˜)\n",
                "test['accident_num'] = test['accident'].apply(lambda x: 0 if x == 'None reported' else 1)\n",
                "test['clean_title_num'] = test['clean_title'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
                "\n",
                "# (5) ì¸ì½”ë”© (Trainì—ì„œ ë§Œë“  ê·œì¹™ì„ Testì—ë„ ì ìš©)\n",
                "target_cols = ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', 'int_col']\n",
                "\n",
                "for col in target_cols:\n",
                "    # Trainì—ì„œ í•™ìŠµí•œ ê°€ê²© ê¸°ì¤€ (Mapping)\n",
                "    if col + '_encoded' in train.columns: # í˜¹ì‹œ Trainì— ìˆìœ¼ë©´ ê·¸ê±° ì“°ê³ , ì—†ìœ¼ë©´ ë‹¤ì‹œ ê³„ì‚°\n",
                "         # (ì£¼ì˜: ì—¬ê¸°ì„  í¸ì˜ìƒ Trainì˜ í˜„ì¬ ìƒíƒœë¥¼ ë¯¿ê³  ê°‘ë‹ˆë‹¤)\n",
                "         pass \n",
                "    \n",
                "    # Train ë°ì´í„°ë¡œ ë§¤í•‘ ê·œì¹™ ë§Œë“¤ê¸°\n",
                "    mapping = train.groupby(col)['price'].median()\n",
                "    \n",
                "    # Testì— ì ìš©\n",
                "    test[col + '_encoded'] = test[col].map(mapping)\n",
                "    # ëª¨ë¥´ëŠ” ê°’ì€ Train ì „ì²´ ì¤‘ì•™ê°’ìœ¼ë¡œ ì±„ìš°ê¸°\n",
                "    test[col + '_encoded'] = test[col + '_encoded'].fillna(train['price'].median())\n",
                "\n",
                "# ---------------------------------------------------------\n",
                "# 3. ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì‚­ì œ (ì£½ì—¬ì•¼ í•  ë†ˆë“¤)\n",
                "# ---------------------------------------------------------\n",
                "# ì‚­ì œí•  ì»¬ëŸ¼ ëª©ë¡ (ì¤‘ê°„ ë³€ìˆ˜, ê¸€ì ë³€ìˆ˜ ë“±)\n",
                "drop_cols = [\n",
                "    'brand', 'model', 'fuel_type', 'engine', 'transmission', \n",
                "    'ext_col', 'int_col', 'accident', 'clean_title', \n",
                "    'transmission_simple', 'ext_col_simple', 'int_col_simple',\n",
                "    'accident_filled', 'ext_col_categorized', 'int_col_categorized' # ì•„ê¹Œ ë²”ì¸ë“¤ ì¶”ê°€!\n",
                "]\n",
                "\n",
                "# Trainê³¼ Testì—ì„œ ë™ì‹œì— ì‚­ì œ (ì—†ìœ¼ë©´ ë¬´ì‹œ)\n",
                "train_final = train.drop(columns=[c for c in drop_cols if c in train.columns], errors='ignore')\n",
                "test_final = test.drop(columns=[c for c in drop_cols if c in test.columns], errors='ignore')\n",
                "\n",
                "# ---------------------------------------------------------\n",
                "# 4. ìµœì¢… ê²€ì‚¬ (ìŒë‘¥ì´ ê²€ì‚¬)\n",
                "# ---------------------------------------------------------\n",
                "print(f\"Train ì»¬ëŸ¼ ê°œìˆ˜: {train_final.shape[1]}\")\n",
                "print(f\"Test  ì»¬ëŸ¼ ê°œìˆ˜: {test_final.shape[1]}\")\n",
                "\n",
                "train_cols = set(train_final.columns)\n",
                "test_cols = set(test_final.columns)\n",
                "\n",
                "missing_in_test = train_cols - test_cols - {'price'}\n",
                "\n",
                "if len(missing_in_test) > 0:\n",
                "    print(f\"ğŸš¨ ì•„ì§ë„ Testì— ì—†ëŠ” ì»¬ëŸ¼ì´ ìˆìŠµë‹ˆë‹¤: {missing_in_test}\")\n",
                "else:\n",
                "    print(\"âœ… ì™„ë²½í•©ë‹ˆë‹¤! Trainê³¼ Testì˜ êµ¬ì¡°ê°€ ë˜‘ê°™ìŠµë‹ˆë‹¤.\")\n",
                "    print(\"   ì´ì œ ëª¨ë¸ í•™ìŠµ(fit)ì„ ì‹œì‘í•˜ì„¸ìš”! ğŸš€\")\n",
                "\n",
                "# (ì°¸ê³ ) ìµœì¢… ë°ì´í„° ì¤€ë¹„\n",
                "# X = train_final.drop('price', axis=1)\n",
                "# y = train_final['price']\n",
                "# target_test = test_final"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =========================================================\n",
                "# 1. ì´ë€ì„± ìŒë‘¥ì´ ì •ë¦¬ (ì¤‘ë³µ ë³€ìˆ˜ ì œê±°)\n",
                "# =========================================================\n",
                "# model_yearì™€ car_ageëŠ” ì‚¬ì‹¤ìƒ ê°™ì€ ì •ë³´ì…ë‹ˆë‹¤.\n",
                "# ë‘˜ ì¤‘ í•˜ë‚˜ë¥¼ ì§€ì›Œì•¼ ëª¨ë¸ì´ ê¹”ë”í•´ì§‘ë‹ˆë‹¤.\n",
                "if 'model_year' in train_final.columns and 'car_age' in train_final.columns:\n",
                "    print(\"âœ‚ï¸ ì¤‘ë³µ ë³€ìˆ˜ ì œê±°: 'model_year'ë¥¼ ì‚­ì œí•˜ê³  'car_age'ë§Œ ë‚¨ê¹ë‹ˆë‹¤.\")\n",
                "    train_final = train_final.drop('model_year', axis=1)\n",
                "    test_final = test_final.drop('model_year', axis=1)\n",
                "\n",
                "# =========================================================\n",
                "# 2. ì •ë‹µ(Price) ë¶„í¬ í™•ì¸ ë° ë¡œê·¸ ë³€í™˜ (ê°€ì¥ ì¤‘ìš”!!!)\n",
                "# =========================================================\n",
                "target = train_final['price']\n",
                "\n",
                "plt.figure(figsize=(10, 4))\n",
                "\n",
                "# (1) ë³€í™˜ ì „ (ì›ë³¸)\n",
                "plt.subplot(1, 2, 1)\n",
                "sns.histplot(target, kde=True, color='orange')\n",
                "plt.title(f'Original Price (Skewness: {target.skew():.2f})')\n",
                "\n",
                "# (2) ë¡œê·¸ ë³€í™˜ í›„ (Target Transformation)\n",
                "# ë¡œê·¸ë¥¼ ì”Œìš°ë©´ í•œìª½ìœ¼ë¡œ ì ë¦° ë°ì´í„°ê°€ ì •ê·œë¶„í¬ì²˜ëŸ¼ ì˜ˆì˜ê²Œ í´ì§‘ë‹ˆë‹¤.\n",
                "target_log = np.log1p(target)\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "sns.histplot(target_log, kde=True, color='green')\n",
                "plt.title(f'Log Transformed Price (Skewness: {target_log.skew():.2f})')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"âœ… ë¶„í¬ê°€ ì˜¤ë¥¸ìª½(ì´ˆë¡ìƒ‰)ì²˜ëŸ¼ ì¢… ëª¨ì–‘ì— ê°€ê¹Œì›Œì•¼ í•™ìŠµì´ ì˜ ë©ë‹ˆë‹¤!\")\n",
                "\n",
                "# =========================================================\n",
                "# 3. í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ\n",
                "# =========================================================\n",
                "# X: í•™ìŠµ ë¬¸ì œì§€ (price ëºŒ)\n",
                "X = train_final.drop('price', axis=1)\n",
                "\n",
                "# y: ì •ë‹µì§€ (ë¡œê·¸ ë³€í™˜ ì ìš©!)\n",
                "# ì£¼ì˜: ë‚˜ì¤‘ì— ì˜ˆì¸¡ê°’ ë‚¼ ë•Œ np.expm1()ìœ¼ë¡œ ë‹¤ì‹œ ë˜ëŒë ¤ì•¼ í•¨!\n",
                "y = np.log1p(train_final['price'])\n",
                "\n",
                "# Test: ì‹¤ì „ ë¬¸ì œì§€\n",
                "target_test = test_final\n",
                "\n",
                "print(f\"\\nğŸš€ ëª¨ë¸ í•™ìŠµ ì¤€ë¹„ ì™„ë£Œ!\")\n",
                "print(f\"X shape: {X.shape}\")\n",
                "print(f\"y shape: {y.shape}\")\n",
                "print(f\"Test shape: {target_test.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **ëª¨ë¸ ëŒë¦¬ê¸°**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from xgboost import XGBRegressor\n",
                "from sklearn.model_selection import KFold\n",
                "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_squared_log_error\n",
                "\n",
                "# ---------------------------------------------------------\n",
                "# 1. í•™ìŠµ ë°ì´í„° ì¤€ë¹„ (ìë™ìœ¼ë¡œ ìˆ«ìë§Œ ê³¨ë¼ë‚´ê¸°)\n",
                "# ---------------------------------------------------------\n",
                "# 'price'ëŠ” ì •ë‹µì´ë‹ˆê¹Œ ë¹¼ê³ , ë‚˜ë¨¸ì§€ ì¤‘ì—ì„œ 'ìˆ«ì' ì»¬ëŸ¼ë§Œ Xë¡œ ì”ë‹ˆë‹¤.\n",
                "X = train.drop('price', axis=1).select_dtypes(exclude=['object'])\n",
                "y = np.log1p(train['price']) # ì •ë‹µì€ ë¡œê·¸ ë³€í™˜!\n",
                "\n",
                "print(f\"âœ… í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(X)}ê°œ ìƒ˜í”Œ\")\n",
                "print(f\"   (ì‚¬ìš©ëœ ì»¬ëŸ¼: {len(X.columns)}ê°œ)\")\n",
                "\n",
                "# ---------------------------------------------------------\n",
                "# 2. 5-Fold êµì°¨ ê²€ì¦ (ì ìˆ˜ ì±„ì )\n",
                "# ---------------------------------------------------------\n",
                "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
                "scores = {'rmsle':[], 'rmse':[], 'mae':[], 'r2':[]}\n",
                "\n",
                "# ëª¨ë¸ ì„¤ì •\n",
                "model = XGBRegressor(\n",
                "    n_estimators=1000, \n",
                "    learning_rate=0.05, \n",
                "    max_depth=6, \n",
                "    random_state=42, \n",
                "    n_jobs=-1\n",
                ")\n",
                "\n",
                "print(\"\\nğŸš€ [1ë‹¨ê³„] êµì°¨ ê²€ì¦(ì ìˆ˜ í™•ì¸) ì‹œì‘...\")\n",
                "\n",
                "for i, (t_idx, v_idx) in enumerate(kf.split(X, y)):\n",
                "    X_t, X_v = X.iloc[t_idx], X.iloc[v_idx]\n",
                "    y_t, y_v = y.iloc[t_idx], y.iloc[v_idx]\n",
                "    \n",
                "    # í•™ìŠµ\n",
                "    model.fit(X_t, y_t)\n",
                "    \n",
                "    # ì˜ˆì¸¡ ë° ì›ë˜ ê°€ê²©ìœ¼ë¡œ ë³µêµ¬ (Log -> Real)\n",
                "    pred_real = np.expm1(model.predict(X_v))\n",
                "    y_real = np.expm1(y_v)\n",
                "    \n",
                "    # ì§€í‘œ ê³„ì‚°\n",
                "    mae = mean_absolute_error(y_real, pred_real)\n",
                "    rmse = np.sqrt(mean_squared_error(y_real, pred_real))\n",
                "    r2 = r2_score(y_real, pred_real)\n",
                "    \n",
                "    # RMSLE (ìŒìˆ˜ ë°©ì§€ ì•ˆì „ì¥ì¹˜)\n",
                "    pred_safe = np.maximum(pred_real, 0)\n",
                "    rmsle = np.sqrt(mean_squared_log_error(y_real, pred_safe))\n",
                "    \n",
                "    # ì ìˆ˜ ì €ì¥\n",
                "    scores['rmsle'].append(rmsle)\n",
                "    scores['rmse'].append(rmse)\n",
                "    scores['mae'].append(mae)\n",
                "    scores['r2'].append(r2)\n",
                "    \n",
                "    print(f\"   [Fold {i+1}] RMSLE: {rmsle:.4f} | RÂ²: {r2:.4f}\")\n",
                "\n",
                "# ìµœì¢… ì„±ì í‘œ ì¶œë ¥\n",
                "print(\"\\nğŸ“Š [ìµœì¢… í‰ê·  ì„±ì í‘œ]\")\n",
                "print(f\"   RMSLE : {np.mean(scores['rmsle']):.5f}  (ëª©í‘œ: < 0.2)\")\n",
                "print(f\"   RÂ²    : {np.mean(scores['r2']):.4f}   (ëª©í‘œ: > 0.8)\")\n",
                "print(\"-\" * 50)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ëª¨ë¸ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
                "from xgboost import XGBRegressor\n",
                "from lightgbm import LGBMRegressor\n",
                "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
                "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
                "from sklearn.model_selection import KFold\n",
                "from sklearn.metrics import r2_score, mean_squared_log_error\n",
                "\n",
                "# 1. í•™ìŠµ ë°ì´í„° ì¤€ë¹„ & ë¬´í•œëŒ€/ë¹ˆì¹¸ ì²˜ë¦¬\n",
                "X = train.drop('price', axis=1).select_dtypes(exclude=['object'])\n",
                "y = np.log1p(train['price'])\n",
                "X = X.replace([np.inf, -np.inf], np.nan).fillna(X.median())\n",
                "\n",
                "print(f\"âœ… ì„ ìˆ˜ ì…ì¥ ì™„ë£Œ: {len(X)}ëª… (Ridge íˆ¬ì… ì¤€ë¹„ ë!)\")\n",
                "\n",
                "# 2. ëª¨ë¸ ë¼ì¸ì—… (GB í‡´ì¶œ, Ridge íˆ¬ì…)\n",
                "models = {\n",
                "    \"XGBoost\": XGBRegressor(n_estimators=1000, learning_rate=0.05, max_depth=6, random_state=42, n_jobs=-1),\n",
                "    \"LightGBM\": LGBMRegressor(n_estimators=1000, learning_rate=0.05, max_depth=10, random_state=42, n_jobs=-1, verbose=-1),\n",
                "    \"RandomForest\": RandomForestRegressor(n_estimators=50, max_depth=15, random_state=42, n_jobs=-1),\n",
                "    \"ExtraTrees\": ExtraTreesRegressor(n_estimators=50, max_depth=15, random_state=42, n_jobs=-1),\n",
                "    \"Ridge\": Ridge(alpha=0.01), # <--- ë¹ ë¥´ê³  ê°•ë ¥í•œ ê¸°ì¤€ì !\n",
                "    \"Lasso\": Lasso(alpha=0.01),\n",
                "    \"LinearRegression\":LinearRegression()\n",
                "    \n",
                "}\n",
                "\n",
                "# 3. ì˜¤ë””ì…˜ ì‹œì‘\n",
                "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
                "results = []\n",
                "\n",
                "print(\"\\nğŸš€ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ì‹œì‘! (RÂ²ëŠ” ë†’ì„ìˆ˜ë¡, RMSLEëŠ” ë‚®ì„ìˆ˜ë¡ ì¢‹ìŠµë‹ˆë‹¤)\")\n",
                "\n",
                "for name, model in models.items():\n",
                "    print(f\"\\nğŸ¥Š [{name}] ë‹¬ë¦¬ëŠ” ì¤‘...\", end=\" \")\n",
                "    \n",
                "    r2_scores = []\n",
                "    rmsle_scores = []\n",
                "    \n",
                "    for i, (t_idx, v_idx) in enumerate(kf.split(X, y)):\n",
                "        X_t, X_v = X.iloc[t_idx], X.iloc[v_idx]\n",
                "        y_t, y_v = y.iloc[t_idx], y.iloc[v_idx]\n",
                "        \n",
                "        model.fit(X_t, y_t)\n",
                "        \n",
                "        pred = np.expm1(model.predict(X_v))\n",
                "        pred_safe = np.maximum(pred, 0)\n",
                "        \n",
                "        # ì§€í‘œ ê³„ì‚°\n",
                "        rmsle = np.sqrt(mean_squared_log_error(np.expm1(y_v), pred_safe))\n",
                "        r2 = r2_score(np.expm1(y_v), pred)\n",
                "        \n",
                "        r2_scores.append(r2)\n",
                "        rmsle_scores.append(rmsle)\n",
                "        print(\".\", end=\"\") \n",
                "    \n",
                "    avg_rmsle = np.mean(rmsle_scores)\n",
                "    avg_r2 = np.mean(r2_scores)\n",
                "    \n",
                "    results.append({'Model': name, 'RMSLE': avg_rmsle, 'R2': avg_r2})\n",
                "    # âœ¨ ì—¬ê¸°! RÂ²ë„ ê°™ì´ ì¶œë ¥ë˜ê²Œ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤!\n",
                "    print(f\" ì™„ë£Œ! | RMSLE: {avg_rmsle:.4f} (â†˜) | RÂ²: {avg_r2:.4f} (â†—)\")\n",
                "\n",
                "# 4. ê²°ê³¼ ë°œí‘œ\n",
                "results_df = pd.DataFrame(results).sort_values('RMSLE', ascending=True)\n",
                "\n",
                "print(\"\\nğŸ† [ìµœì¢… ì„±ì í‘œ (RMSLE ìˆœ)]\")\n",
                "print(results_df)\n",
                "\n",
                "# ì‹œê°í™” (ë‘ ê°€ì§€ ì§€í‘œ ë¹„êµ)\n",
                "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
                "\n",
                "# RMSLE (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)\n",
                "sns.barplot(x='RMSLE', y='Model', data=results_df, palette='viridis', ax=ax[0])\n",
                "ax[0].set_title('RMSLE (Lower is Better)')\n",
                "ax[0].set_xlabel('Error (RMSLE)')\n",
                "\n",
                "# RÂ² (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)\n",
                "sns.barplot(x='R2', y='Model', data=results_df.sort_values('R2', ascending=False), palette='magma', ax=ax[1])\n",
                "ax[1].set_title('RÂ² Score (Higher is Better)')\n",
                "ax[1].set_xlabel('Accuracy (RÂ²)')\n",
                "ax[1].set_xlim(0, 1)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "best_model = results_df.iloc[0]['Model']\n",
                "print(f\"\\nğŸ¥‡ ì˜¤ëŠ˜ì˜ ìš°ìŠ¹ ëª¨ë¸: {best_model}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==========================================\n",
                "# 5. [ì¶”ê°€] ì‹¤ì „ íˆ¬ì…! ì•™ìƒë¸” ë° ì œì¶œ íŒŒì¼ ìƒì„±\n",
                "# ==========================================\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# 1) í…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬ (í•™ìŠµ ë°ì´í„°ì™€ ë˜‘ê°™ì´ ë§ì¶°ì£¼ê¸°)\n",
                "# ì£¼ì˜: 'test'ë¼ëŠ” ë°ì´í„°í”„ë ˆì„ì´ ë¡œë“œë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
                "if 'test' in globals():\n",
                "    # í•™ìŠµ ë°ì´í„°(X)ì™€ ë™ì¼í•œ ì»¬ëŸ¼ë§Œ ë‚¨ê¸°ê³ , ìˆ«ìí˜• ë³€í™˜ ë° ë¹ˆì¹¸ ì±„ìš°ê¸°\n",
                "    X_test = test.select_dtypes(exclude=['object'])\n",
                "    \n",
                "    # í•™ìŠµ ë°ì´í„° ì»¬ëŸ¼ ìˆœì„œì™€ ì¼ì¹˜ì‹œí‚¤ê¸° (ì•ˆì „ì„ ìœ„í•´)\n",
                "    # ì—†ëŠ” ì»¬ëŸ¼ì€ 0ìœ¼ë¡œ ì±„ìš°ê³ , í•™ìŠµì— ì—†ë˜ ì»¬ëŸ¼ì€ ë²„ë¦¼\n",
                "    X_test = X_test.reindex(columns=X.columns, fill_value=0)\n",
                "    \n",
                "    # ë¬´í•œëŒ€/ë¹ˆì¹¸ ì²˜ë¦¬ (í•™ìŠµ ë•Œì™€ ë™ì¼í•œ ê°’ ì‚¬ìš© ê¶Œì¥)\n",
                "    X_test = X_test.replace([np.inf, -np.inf], np.nan).fillna(X.median())\n",
                "    \n",
                "    print(f\"\\nâœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(X_test)}ê±´\")\n",
                "else:\n",
                "    print(\"ğŸš¨ 'test' ë°ì´í„°í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ë¡œë“œí•´ì£¼ì„¸ìš”!\")\n",
                "\n",
                "# 2) ì „ì²´ ë°ì´í„°ë¡œ ì¬í•™ìŠµ ë° ì˜ˆì¸¡\n",
                "# K-FoldëŠ” ê²€ì¦ìš©ì´ì—ˆìœ¼ë¯€ë¡œ, ì´ì œ ì „ì²´ ë°ì´í„°(X, y)ë¡œ ëª¨ë¸ì„ ë‹¤ì‹œ ê½‰ ì±„ì›Œì„œ í•™ìŠµì‹œí‚µë‹ˆë‹¤.\n",
                "final_predictions = {}\n",
                "\n",
                "print(\"\\nğŸ¤– ì „ì²´ ë°ì´í„°ë¡œ ì¬í•™ìŠµ ë° ì˜ˆì¸¡ ì‹œì‘...\")\n",
                "\n",
                "for name, model in models.items():\n",
                "    # ì „ì²´ ë°ì´í„°ë¡œ ì¬í•™ìŠµ\n",
                "    model.fit(X, y)\n",
                "    \n",
                "    # ì˜ˆì¸¡ (ë¡œê·¸ ìŠ¤ì¼€ì¼ ê²°ê³¼)\n",
                "    pred_log = model.predict(X_test)\n",
                "    \n",
                "    # ë¡œê·¸ -> ì›ë˜ ê°€ê²© ë³µêµ¬ (np.expm1)\n",
                "    pred_real = np.expm1(pred_log)\n",
                "    \n",
                "    # í˜¹ì‹œ ëª¨ë¥¼ ìŒìˆ˜ê°’ ë°©ì§€\n",
                "    final_predictions[name] = np.maximum(pred_real, 0)\n",
                "    print(f\"   - {name} ì˜ˆì¸¡ ì™„ë£Œ\")\n",
                "\n",
                "# 3) ì•™ìƒë¸” (ê°€ì¤‘ì¹˜ ë¸”ë Œë”©)\n",
                "# ì „ëµ: 1ë“± ëª¨ë¸ì— 50% ì‹ ë¢°ë¥¼ ì£¼ê³ , ë‚˜ë¨¸ì§€ 50%ëŠ” ë‹¤ë¥¸ ëª¨ë¸ë“¤ì˜ í‰ê· ìœ¼ë¡œ ë³´ì •\n",
                "best_model_name = results_df.iloc[0]['Model'] # ì•„ê¹Œ ì„±ì í‘œ 1ë“±\n",
                "print(f\"\\nğŸ‘‘ ë©”ì¸ ëª¨ë¸({best_model_name}) ìœ„ì£¼ë¡œ ì•™ìƒë¸” ì¡°í•© ì¤‘...\")\n",
                "\n",
                "# 1ë“± ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’\n",
                "main_pred = final_predictions[best_model_name]\n",
                "\n",
                "# ë‚˜ë¨¸ì§€ ëª¨ë¸ë“¤ì˜ ì˜ˆì¸¡ê°’ í‰ê·  (ë‹¨ìˆœ í‰ê· )\n",
                "other_preds = []\n",
                "for name, pred in final_predictions.items():\n",
                "    if name != best_model_name:\n",
                "        other_preds.append(pred)\n",
                "\n",
                "if other_preds:\n",
                "    sub_pred_avg = np.mean(other_preds, axis=0)\n",
                "    # ğŸ’¡ í™©ê¸ˆ ë¹„ìœ¨: 1ë“±(0.6) + ë‚˜ë¨¸ì§€ì—°í•©(0.4) \n",
                "    # (ì„±ëŠ¥ì— ë”°ë¼ ì´ ë¹„ìœ¨ì„ 0.7:0.3 ë“±ìœ¼ë¡œ ì¡°ì ˆí•´ë³´ì„¸ìš”)\n",
                "    final_ensemble_pred = (main_pred * 0.6) + (sub_pred_avg * 0.4)\n",
                "else:\n",
                "    final_ensemble_pred = main_pred\n",
                "\n",
                "print(\"âœ¨ ì•™ìƒë¸” ì™„ë£Œ!\")\n",
                "\n",
                "# 4) ì œì¶œ íŒŒì¼ ì €ì¥ (submission.csvê°€ ìˆë‹¤ê³  ê°€ì •)\n",
                "# ì˜ˆì‹œ: submission = pd.read_csv('sample_submission.csv')\n",
                "# submission['price'] = final_ensemble_pred\n",
                "# submission.to_csv('my_ensemble_submission.csv', index=False)\n",
                "# print(\"\\nğŸ“‚ 'my_ensemble_submission.csv' ì €ì¥ ì™„ë£Œ! ì œì¶œí•´ë³´ì„¸ìš”.\")\n",
                "\n",
                "# (ì œì¶œ íŒŒì¼ ì–‘ì‹ì´ ì—†ë‹¤ë©´ ì•„ë˜ì²˜ëŸ¼ ê²°ê³¼ë§Œ ì €ì¥)\n",
                "output = pd.DataFrame({'id': test.index, 'price': final_ensemble_pred})\n",
                "output.to_csv('ensemble_result.csv', index=False)\n",
                "print(f\"\\nğŸ“‚ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: ensemble_result.csv (ìƒìœ„ 5ê°œ í™•ì¸)\")\n",
                "print(output.head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ---------------------------------------------------------\n",
                "# 3. ì „ì²´ ë°ì´í„° ì¬í•™ìŠµ & ì˜¤ë‹µ ë…¸íŠ¸ ìƒì„± (ì¸ë±ìŠ¤ ìœ ì§€!)\n",
                "# ---------------------------------------------------------\n",
                "print(\"\\nğŸš€ [2ë‹¨ê³„] ì „ì²´ ë°ì´í„°ë¡œ ì¬í•™ìŠµ ë° ì˜¤ë‹µ ë¶„ì„...\")\n",
                "model.fit(X, y)\n",
                "\n",
                "# ì˜ˆì¸¡ (ì¸ë±ìŠ¤ ìœ ì§€í•˜ë©´ì„œ ì‹œë¦¬ì¦ˆë¡œ ë³€í™˜)\n",
                "pred_log = model.predict(X)\n",
                "pred_series = pd.Series(pred_log, index=X.index) \n",
                "\n",
                "# ê²°ê³¼ í•©ì¹˜ê¸°\n",
                "results = pd.DataFrame({\n",
                "    'Actual': np.expm1(y),       \n",
                "    'Predicted': np.expm1(pred_series),\n",
                "})\n",
                "\n",
                "# ì›ë³¸ ì •ë³´(ë¸Œëœë“œ, ëª¨ë¸ ë“±) ë¶™ì´ê¸°\n",
                "# (trainì— ìˆëŠ” ì»¬ëŸ¼ë§Œ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜µë‹ˆë‹¤)\n",
                "view_cols = ['brand', 'model', 'model_year', 'milage']\n",
                "available_cols = [c for c in view_cols if c in train.columns]\n",
                "results = results.join(train[available_cols])\n",
                "\n",
                "# ì˜¤ì°¨ìœ¨ ê³„ì‚°\n",
                "results['Diff'] = results['Actual'] - results['Predicted']\n",
                "results['Error_Rate'] = np.abs(results['Diff']) / results['Actual'] * 100\n",
                "\n",
                "# Top 10 ì˜¤ë‹µ ì¶œë ¥\n",
                "print(\"\\n=== ğŸš¨ ì§„ì§œ ì˜¤ì°¨ìœ¨ Top 10 (ë²”ì¸ ìƒ‰ì¶œ) ===\")\n",
                "display_cols = available_cols + ['Actual', 'Predicted', 'Error_Rate']\n",
                "print(results.sort_values('Error_Rate', ascending=False)[display_cols].head(10))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **autogluon**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from autogluon.tabular import TabularPredictor\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# =========================================================\n",
                "# 1. [ë°ì´í„° ì”½í¬ ë§ì¶”ê¸°] Train/Test ì»¬ëŸ¼ ë™ê¸°í™”\n",
                "# =========================================================\n",
                "print(\"ğŸ”§ ë°ì´í„° ì»¬ëŸ¼ ë™ê¸°í™” ì¤‘...\")\n",
                "\n",
                "target = 'price'\n",
                "\n",
                "# 1) Trainê³¼ Testì˜ ê³µí†µ ì»¬ëŸ¼ ì°¾ê¸° (ì—ëŸ¬ ì›ì²œ ì°¨ë‹¨)\n",
                "#    (Trainì—ë§Œ ìˆê³  Testì— ì—†ëŠ” í”¼ì²˜ê°€ ë“¤ì–´ê°€ë©´ ì—ëŸ¬ê°€ ë‚©ë‹ˆë‹¤)\n",
                "train_cols = set(train.columns)\n",
                "test_cols = set(test.columns)\n",
                "\n",
                "# êµì§‘í•© ì»¬ëŸ¼ + íƒ€ê²Ÿ ë³€ìˆ˜\n",
                "common_cols = list(train_cols.intersection(test_cols))\n",
                "train_final = train[common_cols + [target]].copy() # í•™ìŠµìš© (íƒ€ê²Ÿ í¬í•¨)\n",
                "test_final = test[common_cols].copy()             # ì˜ˆì¸¡ìš© (íƒ€ê²Ÿ ì œì™¸)\n",
                "\n",
                "print(f\"âœ… í•™ìŠµ ë°ì´í„° ì»¬ëŸ¼ ìˆ˜: {train_final.shape[1]}\")\n",
                "print(f\"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ì»¬ëŸ¼ ìˆ˜: {test_final.shape[1]}\")\n",
                "\n",
                "# =========================================================\n",
                "# 2. [AutoGluon í•™ìŠµ] best Quality ì„¤ì •\n",
                "# =========================================================\n",
                "print(\"\\nğŸ¤– AutoGluon í•™ìŠµ ì‹œì‘ (best Quality)...\")\n",
                "\n",
                "# ì €ì¥í•  í´ë” ì´ë¦„ (ê¸°ì¡´ í´ë”ì™€ ê²¹ì¹˜ì§€ ì•Šê²Œ ì´ë¦„ ë³€ê²½)\n",
                "save_path = 'ag_models_high_quality'\n",
                "\n",
                "predictor = TabularPredictor(\n",
                "    label=target, \n",
                "    problem_type='regression',\n",
                "    eval_metric='root_mean_squared_error',\n",
                "    path=save_path\n",
                ").fit(\n",
                "    train_data=train_final,\n",
                "    presets='best_quality', \n",
                "    time_limit=600,           # â±ï¸ ì œí•œì‹œê°„: 10ë¶„ (600ì´ˆ). ì¶©ë¶„í•©ë‹ˆë‹¤.\n",
                ")\n",
                "\n",
                "# =========================================================\n",
                "# 3. [ìˆ˜ì •ëœ ì˜ˆì¸¡ ì½”ë“œ] inf í•´ê²°!\n",
                "# =========================================================\n",
                "print(\"\\nğŸ”® ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...\")\n",
                "\n",
                "# AutoGluonì´ ì˜ˆì¸¡í•œ ê°’ (ì´ë¯¸ ì›ë˜ ê°€ê²©ì…ë‹ˆë‹¤!)\n",
                "preds = predictor.predict(test_final)\n",
                "\n",
                "# np.expm1ì„ ì“°ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ì”ë‹ˆë‹¤.\n",
                "final_pred = preds \n",
                "\n",
                "# í˜¹ì‹œ ëª¨ë¥¼ ìŒìˆ˜ê°’ë§Œ 0ìœ¼ë¡œ ë³´ì •\n",
                "final_pred = np.maximum(final_pred, 0)\n",
                "\n",
                "# =========================================================\n",
                "# 4. [ì œì¶œ íŒŒì¼ ìƒì„±]\n",
                "# =========================================================\n",
                "submission = pd.read_csv('/Users/choiseoyeon/github/sklearn-est15th/team assignment/choiseoyeon.car/data/sample_submission.csv')\n",
                "submission['price'] = final_pred\n",
                "submission.to_csv('autogluon_fixed_submission.csv', index=False)\n",
                "\n",
                "print(\"\\nğŸ‰ [ì™„ë£Œ] 'autogluon_fixed_submission.csv' ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
                "print(submission.head())"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "DS",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
